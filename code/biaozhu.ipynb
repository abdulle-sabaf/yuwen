{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "现代汉语拼音标注引擎（轻量级教学版）\n",
    "环境要求：Python 3.8+，仅需pypinyin和jieba两个依赖库\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from pypinyin import pinyin, Style, load_phrases_dict, load_single_dict\n",
    "from outils import load_cn_json, dump_cn_json, dump_cn_json_compact\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"xiandaihaiyuchangyongcibiao.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制作中文词语到拼音的映射\n",
    "ciyin = {}  # 词语拼音映射表，将中文词语映射到它的拼音\n",
    "n0 = 0\n",
    "for line in content:\n",
    "    raws = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "    cy = []\n",
    "    for yin in raws[1].split(\"'\"):\n",
    "        if len(yin) and yin[-1] in \"0123456789\":\n",
    "            cy.append((yin[:-1], int(yin[-1])))\n",
    "        else:\n",
    "            cy.append((yin, 0))\n",
    "            n0 += 1\n",
    "    ciyin[raws[0]] = cy\n",
    "\n",
    "dump_cn_json_compact(\"frequent_word_pinyin.json\", ciyin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55735"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ciyin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Hello' 是否包含小写英文字母: True\n",
      "'WORLD' 是否包含小写英文字母: False\n",
      "'12345' 是否包含小写英文字母: False\n",
      "'abc' 是否包含小写英文字母: True\n",
      "'迸发jin!' 是否包含小写英文字母: True\n",
      "'A1b2C3' 是否包含小写英文字母: True\n"
     ]
    }
   ],
   "source": [
    "def contains_lowercase_letter(s):\n",
    "    \"\"\"\n",
    "    判断字符串中是否包含小写英文字母\n",
    "    :param s: 输入字符串\n",
    "    :return: 如果包含小写英文字母，返回True；否则返回False\n",
    "    \"\"\"\n",
    "    for char in s:\n",
    "        if char.islower():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# 示例测试\n",
    "test_strings = [\"Hello\", \"WORLD\", \"12345\", \"abc\", \"迸发jin!\", \"A1b2C3\"]\n",
    "for test in test_strings:\n",
    "    print(f\"'{test}' 是否包含小写英文字母: {contains_lowercase_letter(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55810"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciyin = load_cn_json(\"frequent_word_pinyin.json\")\n",
    "len(ciyin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"upchars.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "ziyin = {}\n",
    "codeyin = {}\n",
    "codezi = {}\n",
    "valen = {}\n",
    "for line in content[2:]:\n",
    "    if line.startswith(\"U\"):\n",
    "        raws = line.rstrip(\"\\n\").split(\":\")\n",
    "        val = raws[0]\n",
    "        raws = raws[1].split(\"#\")\n",
    "        yin = tuple([a.strip() for a in raws[0].strip().split(\",\")])\n",
    "        zi = raws[1].strip()\n",
    "        codeyin[val] = yin\n",
    "        ziyin[zi] = yin\n",
    "        codezi[val] = zi\n",
    "\n",
    "dump_cn_json_compact(\"large_ziyin.json\", ziyin)\n",
    "dump_cn_json_compact(\"large_ziyin_by_unicode.json\", codeyin)\n",
    "dump_cn_json_compact(\"large_hanzi_by_unicode.json\", codezi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377960, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"upwords.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "n = 2\n",
    "comments = []\n",
    "ciyin = {}\n",
    "for line in content[n:]:\n",
    "    n += 1\n",
    "    raws = [a.strip() for a in line.rstrip(\"\\n\").split(\":\")]\n",
    "    ci = raws[0]\n",
    "    yin = [a.strip() for a in raws[1].split(\"#\")[0].strip().split(\" \")]\n",
    "    ciyin[ci] = yin\n",
    "    if \"#\" in line:\n",
    "        comments.append(line)\n",
    "\n",
    "len(ciyin), len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['you', 3], ['di', 4], ['fang', 4], ['shi', 3]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciyin = load_cn_json(\"large_ciyin.json\")\n",
    "ciyin[\"有的放矢\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "377960"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standard_to_numbered(pinyin_str, fen=False):\n",
    "    \"\"\"\n",
    "    将标准拼音格式（如“zhōng”）转换为字母加数字的格式（如“zhong1”）\n",
    "    输入：\n",
    "    pinyin_str (str): 标准拼音字符串\n",
    "    fen (bool): 是否将输出分开\n",
    "    输出：\n",
    "    无音调拼音加数字（str）或 (拼音,数字) 元组（(str, int)）\n",
    "    \"\"\"\n",
    "    tone_map = {\n",
    "        'ā': 'a1', 'á': 'a2', 'ǎ': 'a3', 'à': 'a4',\n",
    "        'ē': 'e1', 'é': 'e2', 'ě': 'e3', 'è': 'e4',\n",
    "        'ī': 'i1', 'í': 'i2', 'ǐ': 'i3', 'ì': 'i4',\n",
    "        'ō': 'o1', 'ó': 'o2', 'ǒ': 'o3', 'ò': 'o4',\n",
    "        'ū': 'u1', 'ú': 'u2', 'ǔ': 'u3', 'ù': 'u4',\n",
    "        'ǖ': 'v1', 'ǘ': 'v2', 'ǚ': 'v3', 'ǜ': 'v4',\n",
    "        \"ń\": 'n2', \"ň\": 'n3', \"ǹ\": 'n4',\n",
    "        \"m̄\": \"m1\", \"ḿ\": \"m2\", \"m̀\": 'm4'\n",
    "    }\n",
    "\n",
    "    for tone_char, replacement in tone_map.items():\n",
    "        if tone_char in pinyin_str:\n",
    "            if fen:\n",
    "                return (pinyin_str.replace(tone_char, replacement[0]).replace(\"ü\", \"v\"), int(replacement[1]))\n",
    "            else:\n",
    "                return pinyin_str.replace(tone_char, replacement[0]).replace(\"ü\", \"v\") + replacement[1]\n",
    "    \n",
    "    if fen:\n",
    "        return (pinyin_str.replace(\"ü\", \"v\"), 0)\n",
    "    else:\n",
    "        return pinyin_str.replace(\"ü\", \"v\") + \"0\"\n",
    "\n",
    "# print(standard_to_numbered(\"hǎo\"))\n",
    "\n",
    "def check_numbered_pinyin(s):\n",
    "    if \"a\" in s:\n",
    "        pies = s.split(\"a\")\n",
    "        if len(pies) > 2:\n",
    "            return False\n",
    "        for c in pies[0]:\n",
    "            if c in (\"e\", \"o\", \"v\"):\n",
    "                return False\n",
    "        for c in pies[1]:\n",
    "            if c in (\"e\", \"v\", \"u\"):\n",
    "                return False\n",
    "    if \"o\" in s:\n",
    "        pies = s.split(\"o\")\n",
    "        if len(pies) > 2:\n",
    "            return False\n",
    "        for c in pies[0]:\n",
    "            if c in (\"e\", \"v\"):\n",
    "                return False\n",
    "        for c in pies[1]:\n",
    "            if c in (\"a\", \"e\", \"i\", \"v\"):\n",
    "                return False\n",
    "    if \"u\" in s:\n",
    "        pies = s.split(\"u\")\n",
    "        if len(pies) > 2:\n",
    "            return False\n",
    "        for c in pies[0]:\n",
    "            if c in (\"e\", \"v\"):\n",
    "                return False\n",
    "        for c in pies[1]:\n",
    "            if c in (\"e\", \"v\", \"u\"):\n",
    "                return s[0] in (\"j\", \"q\", \"x\") and c == \"e\"\n",
    "    return True\n",
    "\n",
    "def merge_numbered(s, n=0):\n",
    "    return s + str(n)\n",
    "\n",
    "def numbered_to_standard(pinyin_str):\n",
    "    # 检查是否符合拼音规则\n",
    "    if not check_numbered_pinyin(pinyin_str):\n",
    "        print(\"不符合规则\")\n",
    "        return pinyin_str\n",
    "    \n",
    "    # 轻声：结尾没有数字或数字不是1234\n",
    "    if not pinyin_str[-1] in \"0123456789\":\n",
    "        return pinyin_str.replace(\"v\", \"ü\")\n",
    "    elif not pinyin_str[-1] in \"1234\":\n",
    "        return pinyin_str[:-1].replace(\"v\", \"ü\")\n",
    "    else:\n",
    "        tone = int(pinyin_str[-1]) - 1  # 1234\n",
    "        tone_map = {\n",
    "            \"a\": ('ā','á','ǎ','à'),\n",
    "            \"e\": ('ē','é','ě','è'),\n",
    "            \"i\": ('ī','í','ǐ','ì'),\n",
    "            \"o\": ('ō','ó','ǒ','ò'),\n",
    "            \"u\": ('ū','ú','ǔ','ù'),\n",
    "            \"v\": ('ǖ','ǘ','ǚ','ǜ'),\n",
    "            \"n\": (\"n\",\"ń\",\"ň\",\"ǹ\"),\n",
    "            \"m\": (\"m̄\",\"ḿ\",\"m\",\"m̀\")\n",
    "        }\n",
    "\n",
    "        for c in pinyin_str:  # 如果有a或e则标在上面\n",
    "            if c in (\"a\", \"e\"):\n",
    "                return pinyin_str[:-1].replace(c, tone_map[c][tone]).replace(\"v\", \"ü\")\n",
    "        for c in pinyin_str:  # 否则如果有o就标在o上面（ou, io）\n",
    "            if c == \"o\":\n",
    "                return pinyin_str[:-1].replace(c, tone_map[c][tone]).replace(\"v\", \"ü\")\n",
    "        for c in pinyin_str:  # 否则如果有i或u就标在上面（i, u, iu, ui），并列时标在后\n",
    "            if c in (\"i\", \"u\"):\n",
    "                if \"i\" in pinyin_str and \"u\" in pinyin_str:\n",
    "                    return pinyin_str[:-1].replace(\"iu\", \"i\"+tone_map[\"u\"][tone]).replace(\"ui\", \"u\"+tone_map[\"i\"][tone]).replace(\"v\", \"ü\")\n",
    "                return pinyin_str[:-1].replace(c, tone_map[c][tone]).replace(\"v\", \"ü\")\n",
    "        for c in pinyin_str:  # 否则如果有v就标在v上面\n",
    "            if c == \"v\":\n",
    "                return pinyin_str[:-1].replace(c, tone_map[c][tone])\n",
    "        for c in pinyin_str:  # 否则标在n或m上面\n",
    "            if c in (\"n\", \"m\"):\n",
    "                return pinyin_str[:-1].replace(c, tone_map[c][tone])\n",
    "        return pinyin_str[:-1]  # 语法正确\n",
    "         \n",
    "# samples = [\"huai2\", \"xue4\", \"hua1\", \"zhuang4\", \"lie4\", \"lve\", \"liao3\", \"huo3\", \"lei2\", \"hui5\", \"kong4\", \"xiong1\", \"mao4\", \"liu6\", \"biang1\", \"jiao4\", \"jia3\", \"ke1\", \"bo1\", \"lu4\", \"yin2\", \"ma0\", \"mai2\", \"xie4\", \"xiu1\", \"xv1\", \"xiang2\", \"ng2\", \"nv3\", \"m2\"]\n",
    "# for sample in samples:\n",
    "#     out = numbered_to_standard(sample)\n",
    "#     back = standard_to_numbered(out, fen=True)\n",
    "#     print(sample, \"-->\", out, \"-->\", back)\n",
    "\n",
    "ciyin_numbered = {}\n",
    "for ci, yins in ciyin.items():\n",
    "    ciyin_numbered[ci] = [standard_to_numbered(yin, fen=True) for yin in yins]\n",
    "\n",
    "len(ciyin_numbered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_cn_json_compact(\"large_ciyin.json\", ciyin_numbered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_xx = \"../src/小学/阅读课文.json\"\n",
    "lessons = load_cn_json(path_xx)\n",
    "# lessons_list = [lessons[k] for k in lessons.keys()]\n",
    "\n",
    "\n",
    "# 中文标点 = \"，。！？“”‘’；：……、《》（）~\"\n",
    "# worded_texts = {}\n",
    "\n",
    "# for idx, lesson in lessons.items():\n",
    "#     worded_texts[idx] = []\n",
    "#     if lesson[\"format\"] == \"散文\":\n",
    "#         for text in lesson[\"content\"]:\n",
    "#             worded_texts[idx].append(jieba.lcut(re.sub(f\"[{中文标点}]\", \"\", re.sub(r\"\\\\apost{.+?}\", \"\", text)), cut_all=False))\n",
    "#     elif lesson[\"format\"] == \"书信\":\n",
    "#         for text in lesson[\"content\"]:\n",
    "#             if not len(text):\n",
    "#                 break\n",
    "#             worded_texts[idx].append(jieba.lcut(re.sub(f\"[{中文标点}]\", \"\", re.sub(r\"\\\\apost{.+?}\", \"\", text)), cut_all=False))\n",
    "#     elif lesson[\"format\"] == \"诗歌\":\n",
    "#         for part in lesson[\"content\"]:\n",
    "#             for text in part:\n",
    "#                 worded_texts[idx].append(jieba.lcut(re.sub(f\"[{中文标点}]\", \"\", re.sub(r\"\\\\apost{.+?}\", \"\", text)), cut_all=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypinyin import pinyin, Style\n",
    "\n",
    "pinyin([\"数\", \"数不清\", \"数数看\", \"掠过\", \"能量\"], style=Style.TONE, heteronym=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抗日战争胜利以后，我在台湾一家航业公司的轮船上工作。\n",
      "有一次，我们的船停泊在高雄港\\apost{fn1}。我上了岸，穿过市区，向郊外走去。不记得走了多远，看到前面有一所乡村小学，白色的围墙，门外栽着一排树。\n",
      "校园里很静，我走近一间教室，站在窗外，见一位年轻的台湾教师正在教孩子们学习祖国的文字。他用粉笔在黑板上一笔一画地写着：\n",
      "“我是中国人，我爱中国。”\n",
      "他写得很认真，也很吃力。台湾“光复”不久，不少教师也是重新学习祖国文字的。\n",
      "接着，他先用闽南语\\apost{fn2}，然后又用还不太熟练的国语，带着孩子们一遍一遍地读。老师和孩子们都显得那么严肃认真，又那么富有感情。好像每个字音，都发自他们火热而真挚的心。\n",
      "我被这动人的情景吸引住了。怀着崇高的敬意，我悄悄地从后门走进教室，在最后一排空位上坐下，和孩子们一起，跟着那位教师，大声地、整齐地、一遍又一遍地朗读着：\n",
      "“我是中国人，我爱中国。”\n",
      "老师和孩子们发现了我，但是，好像谁也没有感到意外。从那一双双眼睛里，可以看出大家对我是欢迎的。课在继续，大家读得更起劲了。\n",
      "下课了，孩子们把我围了起来。\n",
      "老师也走了过来。他热情地和我握了握手，说；“我的国语讲得不好，是初学的。你知道，在日本统治时期，我们上的都是日本人办的学校，讲国语是不准许的。”\n",
      "“我觉得，你今天这一课上得好极了！你教得很有感情，孩子们学得也很有感情。”\n",
      "接着，这位老师一定要领我去看一看他们的小礼堂。\n",
      "说是礼堂，不过是一间比较宽敞的屋子。\n",
      "他指着礼堂两面墙上新画的几幅中国历代伟人像，说：“这里原来画的都是日本人，现在‘光复’了，画上了我们中国自己的伟人。”我看到上面有孔子，有诸葛亮，有郑成功\\apost{fn3}，还有孙中山。看着看着，我的眼睛不觉湿润了。这是多么强烈的民族精神，多么深厚的爱国情意啊！\n",
      "我紧紧地握着这位年轻的台湾教师的手，激动地重复着他刚才教给孩子们的那句话：“我是中国人，我爱中国。”还有什么别的话比这句最简单的话，更能表达我此时的全部感情呢？\n"
     ]
    }
   ],
   "source": [
    "# yins = []\n",
    "# for para in worded_texts[\"杏儿熟了\"]:\n",
    "    # print(para)\n",
    "    # for text in para:\n",
    "    #     yins = pinyin(text, style=Style.TONE, heteronym=False)\n",
    "    #     print(text, \"\\t\\t\", \" \".join([yin[0] for yin in yins]))\n",
    "    # print(\"--\")\n",
    "\n",
    "# len(yins), len(para)\n",
    "\n",
    "title = \"难忘的一课\"\n",
    "seq = \"\"\n",
    "i = 0\n",
    "for para in lessons[title][\"content\"]:\n",
    "    seq += para\n",
    "    i += 1\n",
    "    print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'海的颜色由绿变蓝，由'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 257\n",
    "seq[n-5:n+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinyin_prompt = \"\"\"你是一个辅助中小学语文教学研究机构的人工智能。现在有这样一个问题：中小学语文教学中有大量的中文文本需要标注拼音。这些文本以小学和初中水平的高水平散文、诗歌和小说片段为主，作为课文和阅读材料使用。暂时不考虑文言文、古诗文和方言的问题，仅针对标准高水平的现代白话文进行拼音标注。\n",
    "现在请你直接为以下将课文转为拼音，并评估你对结果的置信度。如果有对某个字的标注结果感到不确定，请在全部标注完后单独列出。\n",
    "具体格式为：返回两个结果。第一个结果为把课文的汉字转成拼音的拼音序列。以每个字的拼音为单位，之间用空格隔开。原地保留原文的标点符号。第二个结果是附带的表格，陈列对标注结果感到不确定的字的置信度信息。请你设定一个置信度评价方式和下限，你觉得你对哪些字转化的拼音信心不够，就把它放进表格里。表格以逗号分隔（csv格式），一共5列，列名为：字, 所在位置, 拼音, 置信度, 是否多音字。其中”所在位置“表示这个字在原文中是第几个字（包含标点符号）。\n",
    "要转化的课文正文如下：\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "工农兵\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['工人', '力量', '大'],\n",
       " ['农民', '力量', '大'],\n",
       " ['士兵', '力量', '大'],\n",
       " ['好好学习', '天天向上'],\n",
       " ['团结起来', '保卫国家'],\n",
       " ['中国', '人民', '大团结', '世界', '人民', '大团结']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def load_textbook(path):\n",
    "    textbook = load_cn_json(path)\n",
    "    \n",
    "    nx = np.sort(np.array([text['numero'] for _, text in textbook.items()]))\n",
    "    lessons = []\n",
    "    for i in nx:\n",
    "        for _, text in textbook.items():\n",
    "            if text['numero'] == i:\n",
    "                lessons.append(text)\n",
    "    for lesson in lessons:\n",
    "        lesson[\"numero\"] = int((lesson[\"numero\"] + 1) / 10)\n",
    "\n",
    "    return lessons\n",
    "\n",
    "# path_sz = \"../src/小学/发蒙识字.json\"\n",
    "# lessons = load_textbook(path_sz)\n",
    "path_xx = \"../src/小学/阅读课文.json\"\n",
    "lessons = load_cn_json(path_xx)\n",
    "lesson = lessons[14]\n",
    "print(lesson[\"title\"])\n",
    "\n",
    "中文标点 = \"，。！？“”‘’；：……、《》（）~\"\n",
    "\n",
    "words = []\n",
    "for text in lesson[\"content\"]:\n",
    "    words.append(jieba.lcut(re.sub(f\"[{中文标点}]\", \"\", text), cut_all=False))\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['工人', '力量', '大', '。'],\n",
       " ['农民', '力量', '大', '。'],\n",
       " ['士兵', '力量', '大', '。'],\n",
       " ['好好学习', '，', '天天向上', '。'],\n",
       " ['团结起来', '，', '保卫国家', '。'],\n",
       " ['中国', '人民', '大团结', '，', '世界', '人民', '大团结', '。']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['wǒ',\n",
       "  'men',\n",
       "  'jiā',\n",
       "  'yuàn',\n",
       "  'zi',\n",
       "  'lǐ',\n",
       "  'yǒu',\n",
       "  'yī',\n",
       "  'kē',\n",
       "  'dà',\n",
       "  'xìng',\n",
       "  'shù',\n",
       "  '。',\n",
       "  'měi',\n",
       "  'nián',\n",
       "  'dào',\n",
       "  'le',\n",
       "  'mài',\n",
       "  'shōu',\n",
       "  'shí',\n",
       "  'jié',\n",
       "  '，',\n",
       "  'shù',\n",
       "  'shàng',\n",
       "  'jiù',\n",
       "  'jié',\n",
       "  'mǎn',\n",
       "  'le',\n",
       "  'huáng',\n",
       "  'dēng',\n",
       "  'dēng',\n",
       "  'de',\n",
       "  'xìng',\n",
       "  'r',\n",
       "  '。',\n",
       "  'cóng',\n",
       "  'wǒ',\n",
       "  'jiā',\n",
       "  'mén',\n",
       "  'qián',\n",
       "  'lù',\n",
       "  'guò',\n",
       "  'de',\n",
       "  'rén',\n",
       "  '，',\n",
       "  'zǒng',\n",
       "  'yào',\n",
       "  'wàng',\n",
       "  'wang',\n",
       "  'nà',\n",
       "  'kē',\n",
       "  'xìng',\n",
       "  'shù',\n",
       "  '，',\n",
       "  'xiàn',\n",
       "  'mù',\n",
       "  'dì',\n",
       "  'shuō',\n",
       "  'dào',\n",
       "  '：“',\n",
       "  'hē',\n",
       "  '，',\n",
       "  'hǎo',\n",
       "  'xìng',\n",
       "  'r',\n",
       "  'ya',\n",
       "  '！”'],\n",
       " ['xìng',\n",
       "  'shù',\n",
       "  'shì',\n",
       "  'nǎi',\n",
       "  'nai',\n",
       "  'qīn',\n",
       "  'shǒu',\n",
       "  'zāi',\n",
       "  'de',\n",
       "  '。',\n",
       "  'tīng',\n",
       "  'nǎi',\n",
       "  'nai',\n",
       "  'shuō',\n",
       "  '，',\n",
       "  'zāi',\n",
       "  'xìng',\n",
       "  'shù',\n",
       "  'de',\n",
       "  'shí',\n",
       "  'hòu',\n",
       "  'hái',\n",
       "  'méi',\n",
       "  'yǒu',\n",
       "  'wǒ',\n",
       "  'ne',\n",
       "  '。',\n",
       "  'yǒu',\n",
       "  'yī',\n",
       "  'huí',\n",
       "  '，',\n",
       "  'wǒ',\n",
       "  'wēi',\n",
       "  'yī',\n",
       "  'zài',\n",
       "  'nǎi',\n",
       "  'nai',\n",
       "  'de',\n",
       "  'huái',\n",
       "  'lǐ',\n",
       "  'wèn',\n",
       "  'tā',\n",
       "  '：“',\n",
       "  'nǎi',\n",
       "  'nai',\n",
       "  '，',\n",
       "  'zán',\n",
       "  'men',\n",
       "  'jiā',\n",
       "  'shù',\n",
       "  'shàng',\n",
       "  'de',\n",
       "  'xìng',\n",
       "  'r',\n",
       "  'yǒu',\n",
       "  'duō',\n",
       "  'shǎo',\n",
       "  'gè',\n",
       "  '？”'],\n",
       " ['“',\n",
       "  'duō',\n",
       "  'de',\n",
       "  'shǔ',\n",
       "  'bù',\n",
       "  'qīng',\n",
       "  'a',\n",
       "  '。',\n",
       "  'yào',\n",
       "  'bù',\n",
       "  '，',\n",
       "  'nǐ',\n",
       "  'shǔ',\n",
       "  'shu',\n",
       "  'kàn',\n",
       "  '。”'],\n",
       " ['wǒ',\n",
       "  'yǎng',\n",
       "  'zhe',\n",
       "  'tóu',\n",
       "  'shǔ',\n",
       "  'qǐ',\n",
       "  'lái',\n",
       "  '，“',\n",
       "  'yī',\n",
       "  '、',\n",
       "  'èr',\n",
       "  '、',\n",
       "  'sān',\n",
       "  '……”',\n",
       "  'shǔ',\n",
       "  'ya',\n",
       "  '，',\n",
       "  'shǔ',\n",
       "  'ya',\n",
       "  '，',\n",
       "  'shǔ',\n",
       "  'dào',\n",
       "  'hòu',\n",
       "  'lái',\n",
       "  'jiù',\n",
       "  'hú',\n",
       "  'tu',\n",
       "  'le',\n",
       "  '。',\n",
       "  'nǎi',\n",
       "  'nai',\n",
       "  'rěn',\n",
       "  'bù',\n",
       "  'zhù',\n",
       "  'xiào',\n",
       "  'le',\n",
       "  '。',\n",
       "  'wǒ',\n",
       "  'bù',\n",
       "  'zhī',\n",
       "  'dào',\n",
       "  'nǎi',\n",
       "  'nai',\n",
       "  'shì',\n",
       "  'xiào',\n",
       "  'wǒ',\n",
       "  'shǎ',\n",
       "  '，',\n",
       "  'hái',\n",
       "  'shì',\n",
       "  'xiào',\n",
       "  'xìng',\n",
       "  'r',\n",
       "  'duō',\n",
       "  '。'],\n",
       " ['zhè',\n",
       "  'yī',\n",
       "  'nián',\n",
       "  'xìng',\n",
       "  'zi',\n",
       "  'yòu',\n",
       "  'shú',\n",
       "  'le',\n",
       "  '。',\n",
       "  'yǒu',\n",
       "  'yī',\n",
       "  'tiān',\n",
       "  '，',\n",
       "  'nǎi',\n",
       "  'nai',\n",
       "  'zhèng',\n",
       "  'zài',\n",
       "  'zuò',\n",
       "  'fàn',\n",
       "  '，',\n",
       "  'hū',\n",
       "  'rán',\n",
       "  'tīng',\n",
       "  'jiàn',\n",
       "  'yǒu',\n",
       "  'hái',\n",
       "  'zi',\n",
       "  'zài',\n",
       "  'kū',\n",
       "  '。',\n",
       "  'nǎi',\n",
       "  'nai',\n",
       "  'jí',\n",
       "  'máng',\n",
       "  'zǒu',\n",
       "  'chū',\n",
       "  'qù',\n",
       "  '，',\n",
       "  'yuán',\n",
       "  'lái',\n",
       "  'shì',\n",
       "  'lín',\n",
       "  'jū',\n",
       "  'jiā',\n",
       "  'de',\n",
       "  'xiǎo',\n",
       "  'táo',\n",
       "  'tao',\n",
       "  'tōu',\n",
       "  'zhāi',\n",
       "  'xìng',\n",
       "  'r',\n",
       "  '，',\n",
       "  'bù',\n",
       "  'xiǎo',\n",
       "  'xīn',\n",
       "  'cóng',\n",
       "  'shù',\n",
       "  'shàng',\n",
       "  'shuāi',\n",
       "  'xià',\n",
       "  'lái',\n",
       "  'le',\n",
       "  '。',\n",
       "  'yī',\n",
       "  'kuài',\n",
       "  'er',\n",
       "  'lái',\n",
       "  'de',\n",
       "  'xiǎo',\n",
       "  'huǒ',\n",
       "  'bàn',\n",
       "  'jiàn',\n",
       "  'le',\n",
       "  'nǎi',\n",
       "  'nai',\n",
       "  'dōu',\n",
       "  'dī',\n",
       "  'xià',\n",
       "  'le',\n",
       "  'tóu',\n",
       "  '，',\n",
       "  'bù',\n",
       "  'gǎn',\n",
       "  'zhī',\n",
       "  'shēng',\n",
       "  '。',\n",
       "  'wǒ',\n",
       "  'méi',\n",
       "  'hǎo',\n",
       "  'qì',\n",
       "  'dì',\n",
       "  'shuō',\n",
       "  '：“',\n",
       "  'nǐ',\n",
       "  'men',\n",
       "  'zhè',\n",
       "  'xiē',\n",
       "  'chán',\n",
       "  'hóu',\n",
       "  'er',\n",
       "  '，',\n",
       "  'tōu',\n",
       "  'chī',\n",
       "  'rén',\n",
       "  'jiā',\n",
       "  'de',\n",
       "  'dōng',\n",
       "  'xi',\n",
       "  '，',\n",
       "  'shuāi',\n",
       "  'le',\n",
       "  'huó',\n",
       "  'gāi',\n",
       "  '！”'],\n",
       " ['wǒ',\n",
       "  'xīn',\n",
       "  'lǐ',\n",
       "  'xiǎng',\n",
       "  '：“',\n",
       "  'kàn',\n",
       "  'wǒ',\n",
       "  'nǎi',\n",
       "  'nai',\n",
       "  'zěn',\n",
       "  'me',\n",
       "  'shōu',\n",
       "  'shi',\n",
       "  'nǐ',\n",
       "  'men',\n",
       "  '！”',\n",
       "  'nǎi',\n",
       "  'nai',\n",
       "  'zǒu',\n",
       "  'guò',\n",
       "  'qù',\n",
       "  'fú',\n",
       "  'qǐ',\n",
       "  'táo',\n",
       "  'tao',\n",
       "  '，',\n",
       "  'gěi',\n",
       "  'tā',\n",
       "  'róu',\n",
       "  'róu',\n",
       "  'tuǐ',\n",
       "  '，',\n",
       "  'kàn',\n",
       "  'tā',\n",
       "  'méi',\n",
       "  'shāng',\n",
       "  'zhe',\n",
       "  '，',\n",
       "  'jiù',\n",
       "  'zhàn',\n",
       "  'qǐ',\n",
       "  'shēn',\n",
       "  'wǎng',\n",
       "  'wū',\n",
       "  'lǐ',\n",
       "  'zǒu',\n",
       "  '，',\n",
       "  'yòu',\n",
       "  'huí',\n",
       "  'guò',\n",
       "  'tóu',\n",
       "  'lái',\n",
       "  'duì',\n",
       "  'hái',\n",
       "  'zi',\n",
       "  'men',\n",
       "  'shuō',\n",
       "  '：“',\n",
       "  'nǐ',\n",
       "  'men',\n",
       "  'xiān',\n",
       "  'bié',\n",
       "  'zǒu',\n",
       "  '。”'],\n",
       " ['guò',\n",
       "  'le',\n",
       "  'yī',\n",
       "  'huì',\n",
       "  'er',\n",
       "  '，',\n",
       "  'nǎi',\n",
       "  'nai',\n",
       "  'ná',\n",
       "  'le',\n",
       "  'yī',\n",
       "  'gēn',\n",
       "  'cháng',\n",
       "  'zhú',\n",
       "  'gān',\n",
       "  'cóng',\n",
       "  'wū',\n",
       "  'lǐ',\n",
       "  'chū',\n",
       "  'lái',\n",
       "  'le',\n",
       "  '。',\n",
       "  'tā',\n",
       "  'zǒu',\n",
       "  'dào',\n",
       "  'shù',\n",
       "  'xià',\n",
       "  '，',\n",
       "  'tiāo',\n",
       "  'shú',\n",
       "  'le',\n",
       "  'de',\n",
       "  'xìng',\n",
       "  'zi',\n",
       "  'wǎng',\n",
       "  'xià',\n",
       "  'dǎ',\n",
       "  '。',\n",
       "  'tā',\n",
       "  'jiǎo',\n",
       "  'dǐ',\n",
       "  'xià',\n",
       "  'zhàn',\n",
       "  'bú',\n",
       "  'dà',\n",
       "  'wěn',\n",
       "  '，',\n",
       "  'shēn',\n",
       "  'zi',\n",
       "  'chàn',\n",
       "  'chàn',\n",
       "  'wēi',\n",
       "  'wēi',\n",
       "  'de',\n",
       "  '。'],\n",
       " ['xìng',\n",
       "  'r',\n",
       "  'yī',\n",
       "  'gè',\n",
       "  'jiē',\n",
       "  'yī',\n",
       "  'gè',\n",
       "  'luò',\n",
       "  'zài',\n",
       "  'dì',\n",
       "  'shàng',\n",
       "  '。',\n",
       "  'wǒ',\n",
       "  'lián',\n",
       "  'máng',\n",
       "  'wān',\n",
       "  'yāo',\n",
       "  'qù',\n",
       "  'jiǎn',\n",
       "  '，',\n",
       "  'bù',\n",
       "  'yī',\n",
       "  'huì',\n",
       "  'er',\n",
       "  'jiù',\n",
       "  'jiǎn',\n",
       "  'le',\n",
       "  'yī',\n",
       "  'yī',\n",
       "  'dōu',\n",
       "  '。',\n",
       "  'nǎi',\n",
       "  'nai',\n",
       "  'bǎ',\n",
       "  'xiǎo',\n",
       "  'táo',\n",
       "  'tao',\n",
       "  'hé',\n",
       "  'tā',\n",
       "  'de',\n",
       "  'huǒ',\n",
       "  'bàn',\n",
       "  'dōu',\n",
       "  'jiào',\n",
       "  'le',\n",
       "  'guò',\n",
       "  'lái',\n",
       "  '，',\n",
       "  'yī',\n",
       "  'rén',\n",
       "  'fēn',\n",
       "  'gěi',\n",
       "  'wǔ',\n",
       "  'liù',\n",
       "  'gè',\n",
       "  '，',\n",
       "  'shèng',\n",
       "  'xià',\n",
       "  'de',\n",
       "  'jǐ',\n",
       "  'gè',\n",
       "  'gěi',\n",
       "  'le',\n",
       "  'wǒ',\n",
       "  '。',\n",
       "  'kàn',\n",
       "  'tā',\n",
       "  'men',\n",
       "  'chī',\n",
       "  'de',\n",
       "  'nà',\n",
       "  'yàng',\n",
       "  'xiāng',\n",
       "  'tián',\n",
       "  '，',\n",
       "  'nǎi',\n",
       "  'nai',\n",
       "  'de',\n",
       "  'zuǐ',\n",
       "  'jiǎo',\n",
       "  'shàng',\n",
       "  'lù',\n",
       "  'chū',\n",
       "  'le',\n",
       "  'wēi',\n",
       "  'xiào',\n",
       "  '。',\n",
       "  'wǒ',\n",
       "  'yǒu',\n",
       "  'diǎn',\n",
       "  'er',\n",
       "  'bù',\n",
       "  'gāo',\n",
       "  'xìng',\n",
       "  '，',\n",
       "  'nǎi',\n",
       "  'nai',\n",
       "  'què',\n",
       "  'xiào',\n",
       "  'zhe',\n",
       "  'shuō',\n",
       "  '：“',\n",
       "  'guǒ',\n",
       "  'zi',\n",
       "  'dà',\n",
       "  'jiā',\n",
       "  'chī',\n",
       "  'cái',\n",
       "  'xiāng',\n",
       "  'tián',\n",
       "  '。',\n",
       "  'yào',\n",
       "  'jì',\n",
       "  'zhù',\n",
       "  '，',\n",
       "  'xìng',\n",
       "  'r',\n",
       "  'shú',\n",
       "  'le',\n",
       "  '，',\n",
       "  'ràng',\n",
       "  'xiāng',\n",
       "  'qīn',\n",
       "  'men',\n",
       "  'dōu',\n",
       "  'cháng',\n",
       "  'chang',\n",
       "  'xiān',\n",
       "  \"。''\"],\n",
       " ['tīng',\n",
       "  'le',\n",
       "  'nǎi',\n",
       "  'nai',\n",
       "  'de',\n",
       "  'huà',\n",
       "  '，',\n",
       "  'wǒ',\n",
       "  'diǎn',\n",
       "  'le',\n",
       "  'diǎn',\n",
       "  'tóu',\n",
       "  '。',\n",
       "  'yǐ',\n",
       "  'hòu',\n",
       "  '，',\n",
       "  'wǒ',\n",
       "  'měi',\n",
       "  'nián',\n",
       "  'dōu',\n",
       "  'zhào',\n",
       "  'nǎi',\n",
       "  'nai',\n",
       "  'de',\n",
       "  'fēn',\n",
       "  'fù',\n",
       "  '，',\n",
       "  'bǎ',\n",
       "  'shú',\n",
       "  'tòu',\n",
       "  'le',\n",
       "  'de',\n",
       "  'xìng',\n",
       "  'r',\n",
       "  'fēn',\n",
       "  'gěi',\n",
       "  'xiǎo',\n",
       "  'huǒ',\n",
       "  'bàn',\n",
       "  'men',\n",
       "  'chī',\n",
       "  '，',\n",
       "  'yě',\n",
       "  'sòng',\n",
       "  'gěi',\n",
       "  'lín',\n",
       "  'jū',\n",
       "  'de',\n",
       "  'shū',\n",
       "  'shu',\n",
       "  'shěn',\n",
       "  'zi',\n",
       "  'men',\n",
       "  'cháng',\n",
       "  'xiān',\n",
       "  '。'],\n",
       " ['jīn',\n",
       "  'nián',\n",
       "  'de',\n",
       "  'xìng',\n",
       "  'r',\n",
       "  'yòu',\n",
       "  'shú',\n",
       "  'le',\n",
       "  '。',\n",
       "  'wàng',\n",
       "  'zhe',\n",
       "  'huáng',\n",
       "  'dēng',\n",
       "  'dēng',\n",
       "  'de',\n",
       "  'xìng',\n",
       "  'r',\n",
       "  'guà',\n",
       "  'mǎn',\n",
       "  'le',\n",
       "  'zhī',\n",
       "  'tóu',\n",
       "  '，',\n",
       "  'wǒ',\n",
       "  'yǎn',\n",
       "  'qián',\n",
       "  'yòu',\n",
       "  'chū',\n",
       "  'xiàn',\n",
       "  'le',\n",
       "  'nǎi',\n",
       "  'nai',\n",
       "  'chàn',\n",
       "  'chàn',\n",
       "  'wēi',\n",
       "  'wēi',\n",
       "  'dì',\n",
       "  'dǎ',\n",
       "  'xìng',\n",
       "  'r',\n",
       "  'de',\n",
       "  'qíng',\n",
       "  'jǐng',\n",
       "  '。',\n",
       "  'yú',\n",
       "  'shì',\n",
       "  '，',\n",
       "  'wǒ',\n",
       "  'tiāo',\n",
       "  'shú',\n",
       "  'tòu',\n",
       "  'le',\n",
       "  'de',\n",
       "  'xìng',\n",
       "  'r',\n",
       "  'dǎ',\n",
       "  'xià',\n",
       "  'yī',\n",
       "  'xiē',\n",
       "  'lái',\n",
       "  '，',\n",
       "  'gěi',\n",
       "  'xiāng',\n",
       "  'qīn',\n",
       "  'men',\n",
       "  'sòng',\n",
       "  'qù',\n",
       "  '——',\n",
       "  'gěi',\n",
       "  'tā',\n",
       "  'men',\n",
       "  'sòng',\n",
       "  'qù',\n",
       "  'xiāng',\n",
       "  'tián',\n",
       "  '，',\n",
       "  'yě',\n",
       "  'gěi',\n",
       "  'tā',\n",
       "  'men',\n",
       "  'sòng',\n",
       "  'qù',\n",
       "  'xǐ',\n",
       "  'yuè',\n",
       "  '']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"gemini_result.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.readlines()\n",
    "    res_gm = []\n",
    "    for line in content:\n",
    "        if len(line) > 1:\n",
    "            res_gm.append(line[:-1].split(\" \"))\n",
    "\n",
    "with open(\"ds_result.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.readlines()\n",
    "    res_ds = []\n",
    "    for line in content:\n",
    "        if len(line) > 1:\n",
    "            res_ds.append(line[:-1].split(\" \"))\n",
    "\n",
    "res_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSSL 3.0.15 3 Sep 2024\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "print(ssl.OPENSSL_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"0194df5a1ada87ba9623a6dd5d0b3c88\",\"object\":\"chat.completion\",\"created\":1738914011,\"model\":\"deepseek-ai/DeepSeek-V3\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"中国大模型行业在2025年将迎来一系列机遇和挑战，这些机遇和挑战主要来自于技术进步、市场需求、政策支持以及国际竞争等多个方面。\\n\\n### 机遇\\n\\n1. **技术进步**：随着人工智能技术的不断进步，大模型的能力将得到显著提升。深度学习、自然语言处理、计算机视觉等领域的创新将为大模型的发展提供强大的技术支撑。\\n\\n2. **市场需求增长**：随着数字化转型的深入，各行各业对大模型的需求将持续增长。特别是在金融、医疗、教育、制造等领域，大模型的应用将更加广泛。\\n\\n3. **政策支持**：中国政府高度重视人工智能和大数据产业的发展，未来可能会出台更多支持政策，为大模型行业的发展提供良好的政策环境。\\n\\n4. **国际合作与交流**：随着全球化的发展，中国大模型行业将有更多机会参与国际合作与交流，学习借鉴国际先进经验，提升自身竞争力。\\n\\n### 挑战\\n\\n1. **技术瓶颈**：尽管技术进步为大模型的发展提供了动力，但在算法优化、数据处理、模型训练等方面仍存在技术瓶颈需要突破。\\n\\n2. **数据安全与隐私保护**：大模型的训练和应用需要大量的数据，如何在保证数据安全和用户隐私的前提下有效利用数据是一个重要挑战。\\n\\n3. **人才短缺**：大模型的研发和应用需要大量高素质的人才，目前中国在这方面还存在一定的短缺问题。\\n\\n4. **国际竞争加剧**：随着全球范围内对大模型的重视程度不断提高，国际竞争将更加激烈。中国大模型行业需要在技术创新、应用拓展等方面不断提升自身实力以应对国际竞争。\\n\\n综上所述，中国大模型行业在2025年将面临巨大的发展机遇和挑战。通过持续的技术创新、市场拓展、政策支持和人才培养等措施，有望推动行业的健康快速发展。\"},\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":66,\"completion_tokens\":346,\"total_tokens\":412},\"system_fingerprint\":\"\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.siliconflow.cn/v1/chat/completions\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"deepseek-ai/DeepSeek-V3\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"中国大模型行业2025年将会迎来哪些机遇和挑战？\"\n",
    "        }\n",
    "    ],\n",
    "    \"stream\": False,\n",
    "    \"max_tokens\": 512,\n",
    "    \"stop\": [\"null\"],\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.7,\n",
    "    \"top_k\": 50,\n",
    "    \"frequency_penalty\": 0.5,\n",
    "    \"n\": 1,\n",
    "    \"response_format\": {\"type\": \"text\"},\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"description\": \"<string>\",\n",
    "                \"name\": \"<string>\",\n",
    "                \"parameters\": {},\n",
    "                \"strict\": False\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer sk-cvhaokjrvhdscwoxqntyyzvkmnrozlsdrdomyebiwkqfisct\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, json=payload, headers=headers, proxies=None)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "结束方式： stop\n",
      "中国大模型行业在2025年将迎来一系列机遇和挑战，这些机遇和挑战主要来自于技术进步、市场需求、政策支持以及国际竞争等多个方面。\n",
      "\n",
      "### 机遇\n",
      "\n",
      "1. **技术进步**：随着人工智能技术的不断进步，大模型的能力将得到显著提升。深度学习、自然语言处理、计算机视觉等领域的创新将为大模型的发展提供强大的技术支撑。\n",
      "\n",
      "2. **市场需求增长**：随着数字化转型的深入，各行各业对大模型的需求将持续增长。特别是在金融、医疗、教育、制造等领域，大模型的应用将更加广泛。\n",
      "\n",
      "3. **政策支持**：中国政府高度重视人工智能和大数据产业的发展，未来可能会出台更多支持政策，为大模型行业的发展提供良好的政策环境。\n",
      "\n",
      "4. **国际合作与交流**：随着全球化的发展，中国大模型行业将有更多机会参与国际合作与交流，学习借鉴国际先进经验，提升自身竞争力。\n",
      "\n",
      "### 挑战\n",
      "\n",
      "1. **技术瓶颈**：尽管技术进步为大模型的发展提供了动力，但在算法优化、数据处理、模型训练等方面仍存在技术瓶颈需要突破。\n",
      "\n",
      "2. **数据安全与隐私保护**：大模型的训练和应用需要大量的数据，如何在保证数据安全和用户隐私的前提下有效利用数据是一个重要挑战。\n",
      "\n",
      "3. **人才短缺**：大模型的研发和应用需要大量高素质的人才，目前中国在这方面还存在一定的短缺问题。\n",
      "\n",
      "4. **国际竞争加剧**：随着全球范围内对大模型的重视程度不断提高，国际竞争将更加激烈。中国大模型行业需要在技术创新、应用拓展等方面不断提升自身实力以应对国际竞争。\n",
      "\n",
      "综上所述，中国大模型行业在2025年将面临巨大的发展机遇和挑战。通过持续的技术创新、市场拓展、政策支持和人才培养等措施，有望推动行业的健康快速发展。\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    # 将响应内容解析为JSON\n",
    "    return_data = response.json()\n",
    "    # print(list(return_data.keys()))\n",
    "    print(\"结束方式：\", return_data[\"choices\"][0][\"finish_reason\"])\n",
    "    print(return_data[\"choices\"][0][\"message\"][\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSSL 3.0.15 3 Sep 2024\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "print(ssl.OPENSSL_VERSION)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanzi2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
