{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from outils import read, keys, load_cn_json, dump_cn_json, 中转数, 数转中, set_char_colors, nice_print, sort_dict_with\n",
    "\n",
    "def wrap(s, wrapper=\"{}\", keep_wrapper=False):\n",
    "    if s:\n",
    "        return wrapper[0] + s + wrapper[-1]\n",
    "    if keep_wrapper:\n",
    "        return wrapper\n",
    "    return \"\"\n",
    "\n",
    "def make_params(params, wrapper=\"[]\", sep=\",\"):\n",
    "    return wrap(sep.join(params), wrapper)\n",
    "\n",
    "def wrap_env(name, content, params=[], param_wrapper=\"[]\", param_sep=\",\"):\n",
    "    out = r\"\\begin\" + wrap(name) + make_params(params, wrapper=param_wrapper, sep=param_sep) + \"\\n\"\n",
    "    lines = content[:-1].split(\"\\n\")  # presume content ends with \\n\n",
    "    for line in lines:\n",
    "        out += \"    \" + line + \"\\n\"\n",
    "    out += r\"\\end\" + wrap(name) + \"\\n\"\n",
    "    return out\n",
    "\n",
    "def wrap_method(method, content=\"\", wrapper=\"{}\", keep_wrapper=True, params=[], param_wrapper=\"[]\", param_sep=\",\"):\n",
    "    return '\\\\' + method + make_params(params, wrapper=param_wrapper, sep=param_sep) + wrap(content, wrapper=wrapper, keep_wrapper=keep_wrapper)\n",
    "\n",
    "def zihao(n):\n",
    "    return wrap_method(\"zihao\", str(n))\n",
    "\n",
    "def package_update_xcolor(packages, texts):\n",
    "    xcolor = packages[\"xcolor\"]\n",
    "    xcolor[\"defined_colors\"] = {}\n",
    "    for _, text in texts.items():\n",
    "        if \"character_colors\" in text:\n",
    "            for key, val in text[\"character_colors\"].items():\n",
    "                xcolor[\"defined_colors\"][key] = val\n",
    "    packages[\"xcolor\"] = xcolor\n",
    "\n",
    "def make_ctex_env(document_class=\"ctexbook\", document_class_params=(\"12pt\", \"UTF-8\",\"openany\"), packages={\"ctex\": [], \"titlesec\": []}, mainfont=\"Arial\", lineskip=\"4pt\", parskip=\"10pt\", title=\"标题\", author=\"\", date=False, toc=True):\n",
    "    \"\"\"make header and footer for ctexbook environment. \n",
    "    header\n",
    "    1. documentclass and parameters \n",
    "    2. packages\n",
    "    3. geometry and fonts\n",
    "    4. package setups\n",
    "    5. global typesettings\n",
    "    6. begin document\n",
    "    footer\n",
    "    1. end document\n",
    "    \"\"\"\n",
    "    # ## header ##\n",
    "\n",
    "    # document class\n",
    "    header = r\"\\documentclass\"+ make_params(document_class_params) + wrap(document_class) + \"\\n\"\n",
    "    \n",
    "    # packages\n",
    "    packages_str = \"\"\n",
    "    for name in packages:\n",
    "        # print(package)\n",
    "        package_declarations = \"\"\n",
    "        if \"declarations\" in packages[name]:\n",
    "            package_declarations = make_params(packages[name]['declarations'])\n",
    "        packages_str += r\"\\usepackage\" + package_declarations + wrap(name) + \"\\n\"\n",
    "    # print(packages_str)\n",
    "    header += packages_str + \"\\n\"\n",
    "\n",
    "    # geometry <-- geometry package\n",
    "    if \"geometry\" in packages:\n",
    "        geometry = packages[\"geometry\"]\n",
    "        paper_type = geometry[\"paper_size\"]\n",
    "        paddings = geometry[\"paddings\"]\n",
    "        left = paddings[\"left\"]\n",
    "        right = paddings[\"right\"]\n",
    "        top = paddings[\"top\"]\n",
    "        bottom = paddings[\"bottom\"]\n",
    "        header += wrap_method(\"geometry\", f\"{paper_type}paper,left={left},right={right},top={top},bottom={bottom}\") + \"\\n\"\n",
    "    \n",
    "    # fonts\n",
    "    header += r\"\\renewcommand{\\footnotesize}{\\fontsize{8.5pt}{10.5pt}\\selectfont}\" + \"\\n\"\n",
    "    header += wrap_method(\"setmainfont\", mainfont) + \"\\n\"\n",
    "    header += r\"\\setCJKmainfont[BoldFont=STZhongsong]{汉字之美仿宋GBK 免费}\" + \"\\n\"\n",
    "    header += r\"\\xeCJKDeclareCharClass{CJK}{`0 -> `9}\" + \"\\n\"  # apply CJK font to numbers\n",
    "    header += r\"\\xeCJKsetup{AllowBreakBetweenPuncts=true}\" + \"\\n\"  # line alignment\n",
    "\n",
    "    if \"footmisc\" in packages:\n",
    "        footnote_settings_content = \"\".join([\"{\\ding{\"+str(192+i)+\"}}\" for i in range(10)])\n",
    "        footnote_settings = wrap_method(\"DefineFNsymbols\", footnote_settings_content, params=[\"circled\"], param_wrapper=\"{}\")\n",
    "        header += footnote_settings + \"\\n\"\n",
    "        header += wrap_method(\"setfnsymbol\", \"circled\") + \"\\n\"\n",
    "\n",
    "    # package setups\n",
    "    # xpinyin\n",
    "    if \"xpinyin\" in packages:\n",
    "        pyr = packages['xpinyin']['ratio']  # size ratio\n",
    "        vsep = packages['xpinyin']['vsep']  # vertical gap\n",
    "        vsep_str = \"vsep={\" + vsep + \"}\"\n",
    "        hsep = packages['xpinyin']['hsep']  # horizontal gap\n",
    "        hsep_str = \"hsep={\" + f\"{hsep} plus {hsep}\" + \"}\"\n",
    "        header += wrap_method(\"xpinyinsetup\", f\"ratio={pyr},{hsep_str},{vsep_str}\") + \"\\n\"  # pinyin settings\n",
    "\n",
    "    # hanzibox\n",
    "    if \"hanzibox\" in packages:\n",
    "        hanzibox = packages[\"hanzibox\"]\n",
    "        frametype = hanzibox['frametype']\n",
    "        framelinewidth = hanzibox['framelinewidth']\n",
    "        width = hanzibox['width']\n",
    "        resize = hanzibox['resize']\n",
    "        framecolor = hanzibox[\"framecolor\"]\n",
    "        pinyinline = hanzibox['pinyinline']\n",
    "        pinyinf = hanzibox['pinyinf']\n",
    "        pinyincolor = hanzibox['pinyincolor']\n",
    "        charcolor = hanzibox['charcolor']\n",
    "        charf = \"charf={\" + hanzibox[\"charf\"][\"font\"] + hanzibox[\"charf\"][\"fontsize\"] + \"}\"\n",
    "        header += wrap_method(\"hanziboxset\", f\"frametype={frametype},framelinewidth={framelinewidth},width={width},resize={resize},pinyinline={pinyinline},framecolor={framecolor},{charf},pinyinf={pinyinf},pinyincolor={pinyincolor},charcolor={charcolor}\") + \"\\n\"  # hanzibox settings\n",
    "\n",
    "    # package setups\n",
    "    # xcolor\n",
    "    if \"xcolor\" in packages:\n",
    "        defcolor_str = \"\"\n",
    "        for key, (r, g, b) in packages[\"xcolor\"][\"defined_colors\"].items():\n",
    "            rgb_plate = f\"{r},{g},{b}\"\n",
    "            defcolor_str += wrap_method(\"definecolor\", key) + r\"{RGB}{\" + rgb_plate + r\"}\" + \"\\n\"\n",
    "        header += defcolor_str + \"\\n\"\n",
    "\n",
    "    # global typesettings\n",
    "    # title format\n",
    "    header += r\"\\titleformat{\\chapter}{\\zihao{-1}\\bfseries}{ }{16pt}{}\" + \"\\n\"\n",
    "    header += r\"\\titleformat{\\section}{\\zihao{-2}\\bfseries}{ }{0pt}{}\" + \"\\n\"\n",
    "    header += r\"\\title\" + wrap(r\"\\zihao{0} \\bfseries \" + title) + \"\\n\"\n",
    "    # line and paragraph skips\n",
    "    header += r\"\\setlength{\\lineskip}{\" + lineskip + \"}\\n\"  # skip length after line\n",
    "    header += r\"\\setlength{\\parskip}{\" + parskip + \"}\\n\"  # extra skip for paragraphs \n",
    "    # front page format\n",
    "    if author:  # author format\n",
    "        header += r\"\\author{\\zihao{2} \\texttt\" + wrap(author) + \"}\\n\"\n",
    "    else:\n",
    "        header += r\"\\author{}\" + \"\\n\"\n",
    "    if date:  # date format\n",
    "        header += r\"\\date{\\bfseries\\today}\" + \"\\n\"\n",
    "    else:\n",
    "        header += r\"\\date{}\" + \"\\n\"\n",
    "    \n",
    "    # begin document\n",
    "    header += r\"\\begin\" + wrap(\"document\") + \"\\n\"\n",
    "    header += r\"\\maketitle\" + \"\\n\"\n",
    "    if toc:\n",
    "        header += r\"\\tableofcontents\" + \"\\n\"\n",
    "    header += r\"\\newpage\" + \"\\n\"\n",
    "    \n",
    "    # ## footer ##\n",
    "\n",
    "    # end document\n",
    "    footer = r\"\\end\" + wrap(\"document\") + \"\\n\"\n",
    "    return header, footer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印页面设置：纸号，页边距等\n",
    "geometry = {}\n",
    "geometry[\"paper_size\"] = \"a5\"  # 使用A5纸\n",
    "paddings = {}  # 页边距\n",
    "paddings[\"left\"] = \"1.4cm\"\n",
    "paddings[\"right\"] = \"1.4cm\"\n",
    "paddings[\"top\"] = \"2.3cm\"\n",
    "paddings[\"bottom\"] = \"2.3cm\"\n",
    "geometry[\"paddings\"] = paddings\n",
    "\n",
    "# 拼音设置： xpinyin宏包\n",
    "pinyin = {}\n",
    "pinyin[\"ratio\"] = \"0.5\"\n",
    "pinyin[\"hsep\"] = \".6em\"\n",
    "pinyin[\"vsep\"] = \"1em\"\n",
    "\n",
    "# 田字格设置：hanzibox宏包\n",
    "# \\hanziboxset{frametype=咪,framelinewidth=0.5pt,width=1.0cm,resize=real,pinyinline=true,framecolor=red,charf={\\kaishu\\huge},pinyinf=\\scriptsize,pinyincolor=green!30!black,charcolor=green!30!black}\n",
    "hanzibox = {}\n",
    "hanzibox[\"frametype\"] = \"咪\"\n",
    "hanzibox[\"framelinewidth\"] = \"0.5pt\"\n",
    "hanzibox[\"width\"] = \"0.9cm\"\n",
    "hanzibox[\"resize\"] = \"real\"\n",
    "hanzibox[\"pinyinline\"] = \"true\"\n",
    "hanzibox[\"framecolor\"] = \"red\"\n",
    "hanzibox[\"pinyinf\"] = r\"\\scriptsize\"\n",
    "hanzibox[\"charf\"] = {\"font\": r\"\\kaishu\", \"fontsize\": r\"\\huge\"}\n",
    "hanzibox[\"pinyincolor\"] = r\"green!30!black\"\n",
    "hanzibox[\"charcolor\"] = r\"green!30!black\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小学"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_xx = \"../src/小学/\"\n",
    "\n",
    "# 打印小学古诗（分层）\n",
    "packages = {}\n",
    "packages[\"ctex\"] = []\n",
    "packages[\"titlesec\"] = []\n",
    "packages[\"xeCJK\"] = []\n",
    "packages[\"fontspec,xunicode,xltxtra\"] = []\n",
    "packages[\"xpinyin\"] = pinyin\n",
    "packages[\"xpinyin\"]['ratio'] = \"0.44\"\n",
    "packages[\"xpinyin\"]['hsep'] = \".6em\"\n",
    "packages[\"geometry\"] = geometry\n",
    "packages[\"indentfirst\"] = []\n",
    "packages[\"pifont\"] = []\n",
    "packages[\"footmisc\"] = {\"declarations\": [\"perpage\", \"symbol*\"]}\n",
    "lineskip = \"24pt\"\n",
    "parskip = \"6pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 小学诗歌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shi_to_tex_str(shi, print_genre=False, authors={}, typesettings={\"vspaces\": {\"after_title\": 8, \"after_author\": 6, \"after_content\": 6}}):\n",
    "    # convert structured shi to string ready to use in tex\n",
    "    out = r\"\\section{\" + shi[\"title\"] + \"}\\n\\n\"\n",
    "    content = \"\"\n",
    "    # title = wrap_method(\"textbf\", zihao(3) + \" \" + shi[\"title\"]) + \"\\n\\n\"\n",
    "\n",
    "    # if print_genre:\n",
    "    #     title = shi[\"genre\"] + \"：\" + title\n",
    "    # content += title\n",
    "    content += wrap_method(\"vspace\", f\"{typesettings['vspaces']['after_title']}pt\") + \"\\n\\n\"\n",
    "    author_str = \"\"\n",
    "    if shi[\"author\"]:\n",
    "        author = shi[\"author\"]\n",
    "        if author in authors:\n",
    "            author_str += \"〔唐代：\" + author + \"〕\\n\\n\"\n",
    "        else:\n",
    "            author_str += \"〔\" + author + \"〕\\n\\n\"\n",
    "    else:\n",
    "        author_str += \"〔作者不详〕\\n\\n\"\n",
    "    content += wrap_env(\"normalsize\", \"\\n\" + author_str) + \"\\n\"\n",
    "    content += wrap_method(\"vspace\", f\"{typesettings['vspaces']['after_author']}pt\") + \"\\n\\n\"\n",
    "    content += wrap_env(\"large\", \"\\n\" + \"\\n\\n\".join([wrap_method(\"xpinyin*\", line) for line in shi[\"content\"]]) + \"\\n\\n\") + \"\\n\"\n",
    "    content = wrap_env(\"center\", content) + \"\\n\"\n",
    "    content += wrap_method(\"vspace\", f\"{typesettings['vspaces']['after_content']}pt\") + \"\\n\\n\"\n",
    "    out += content\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shis = load_cn_json(os.path.join(path_xx, \"古诗.json\"))\n",
    "output_tex = \"古诗集.tex\"\n",
    "title = \"小学语文古诗集\"\n",
    "# shis = load_cn_json(os.path.join(path_xx, \"唐诗三百首.json\"))\n",
    "# output_tex = \"唐诗三百首.tex\"\n",
    "# title = \"唐诗三百首\"\n",
    "\n",
    "header, footer = make_ctex_env(packages=packages, title=title, parskip=parskip, lineskip=lineskip)\n",
    "\n",
    "# 分层\n",
    "shi_by_level = {}\n",
    "levels = []\n",
    "for i in range(10):\n",
    "    levels.append(f\"第{数转中[i+1]}层\") \n",
    "levels.append(\"其他\")\n",
    "# print(levels)\n",
    "\n",
    "typesettings = {\"vspaces\": {\"after_title\": 10, \"after_author\": 8, \"after_content\": 8}}\n",
    "\n",
    "for title, shi in shis.items():\n",
    "    level = shi[\"level\"]\n",
    "    if level not in shi_by_level:\n",
    "        shi_by_level[level] = {}\n",
    "    shi_by_level[level][title] = shi\n",
    "\n",
    "with open(output_tex, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(header + \"\\n\")\n",
    "    for level in levels:\n",
    "        f.write(r\"\\chapter\" + wrap(level) + \"\\n\\n\")\n",
    "        for title, shi in shi_by_level[level].items():\n",
    "            f.write(shi_to_tex_str(shi, typesettings=typesettings) + \"\\n\")\n",
    "    f.write(footer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xiezi_to_str(zis, ncol=2, nex=3, hspace=1):\n",
    "    out = \"\\n\\n\"\n",
    "    boxes = \"\"\n",
    "    i = 0\n",
    "    for zi in zis:\n",
    "        boxes += wrap_method(\"hanzibox\", zi)\n",
    "        for j in range(nex):\n",
    "            boxes += wrap_method(\"hanzibox\", \"\")\n",
    "        i += 1\n",
    "        if i == ncol:\n",
    "            boxes += \"\\n\\n\"\n",
    "            i = 0\n",
    "        else:\n",
    "            boxes += wrap_method(\"hspace\", f\"{hspace}em\")\n",
    "    out += wrap_env(\"center\", boxes + \"\\n\\n\")\n",
    "    return out\n",
    "\n",
    "print(xiezi_to_str(texts_sz[\"一二三四五\"][\"xiezi\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 小学现代文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(path, format=\"散文\"):\n",
    "    \"\"\"Read raw text and formalize to json\n",
    "    Inputs: \n",
    "    path (str): file path to the raw text.\n",
    "    format (str): format of the text.\n",
    "    Output:\n",
    "    out (dict): a jsonifiable dictionary with formalized text.\n",
    "    Example:\n",
    "    out[\"format\"]     : format of the text (in the sense of tex printing).\n",
    "    out[\"genre\"]      : genre and other tags of the text.\n",
    "    out[\"content\"]    : content of the text. A list of strings.\n",
    "    out[\"grade\"]      : recommanded student grade (for the purpose of eduation).\n",
    "    out[\"title\"]      : title of the text.\n",
    "    out[\"author\"]     : author of the text.\n",
    "    out[\"remarks\"]    : remarks concerning the text.\n",
    "    out[\"footnotes\"]  : footnotes of the content of the text.\n",
    "    out[\"endnotes\"]   : endnotes of the content of the text.\n",
    "    out[\"vocabulary\"] : vocabulary to learn (for the purpose of eduation).\n",
    "    \"\"\"\n",
    "    lines = read(path)\n",
    "    out = {}\n",
    "    title = \"\"\n",
    "    if len(lines) and len(lines[0]):\n",
    "        author = \"\"\n",
    "        grade = 0\n",
    "        footnotes = []\n",
    "        endnotes = []\n",
    "        vocabulary = []\n",
    "        remarks = []\n",
    "        content = []\n",
    "        out[\"format\"] = format\n",
    "        out[\"genre\"] = [format]\n",
    "        # return lines\n",
    "        if format in (\"散文\", \"书信\", \"小说\", \"剧本\"):\n",
    "            for line in lines:\n",
    "                line0 = line.strip()\n",
    "                if line0:\n",
    "                    if not title:\n",
    "                        title = line0\n",
    "                    elif grade < 1 and line.startswith(\"年级：\"):\n",
    "                        grade = int(line0[3:])\n",
    "                    elif not author and line.startswith(\"作者：\"):\n",
    "                        author = line0[3:]\n",
    "                    elif line.startswith(\"备注：\"):\n",
    "                        remarks.append(line0[3:])\n",
    "                    elif line.startswith(\"注释：\"):\n",
    "                        footnotes.append(line0[3:])\n",
    "                    elif line.startswith(\"脚注：\"):\n",
    "                        footnotes.append(line0[3:])\n",
    "                    elif line.startswith(\"尾注：\"):\n",
    "                        endnotes.append(line0[3:])\n",
    "                    elif line.startswith(\"词汇：\"):\n",
    "                        vocabulary.extend(line0[3:].split())\n",
    "                    else:\n",
    "                        content.append(line0)\n",
    "        elif format == \"诗歌\":\n",
    "            para = []\n",
    "            for line in lines:\n",
    "                line0 = line.strip()\n",
    "                if line0:\n",
    "                    if not title:\n",
    "                        title = line0\n",
    "                    elif grade < 1 and line.startswith(\"年级：\"):\n",
    "                        grade = int(line0[3:])\n",
    "                    elif not author and line.startswith(\"作者：\"):\n",
    "                        author = line0[3:]\n",
    "                    elif line.startswith(\"备注：\"):\n",
    "                        remarks.append(line0[3:])\n",
    "                    elif line.startswith(\"注释：\"):\n",
    "                        footnotes.append(line0[3:])\n",
    "                    elif line.startswith(\"脚注：\"):\n",
    "                        footnotes.append(line0[3:])\n",
    "                    elif line.startswith(\"尾注：\"):\n",
    "                        endnotes.append(line0[3:])\n",
    "                    elif line.startswith(\"词汇：\"):\n",
    "                        vocabulary.extend(line0[3:].split())\n",
    "                    else:\n",
    "                        para.append(line0)\n",
    "                elif len(para):\n",
    "                    content.append(\"|#|\".join(para))\n",
    "                    para = []\n",
    "            if len(para):\n",
    "                content.append(para)\n",
    "        # make footnotes dict\n",
    "        footdict = {}\n",
    "        i = 0\n",
    "        keybase = \"fn\"\n",
    "        content = \"@\".join(content)\n",
    "        for note in footnotes:\n",
    "            word = \"\"\n",
    "            if note.startswith(\"〔\"):\n",
    "                word = note.split(\"〕\")[0][1:]\n",
    "                key = keybase + str(i+1)\n",
    "                footdict[key] = note\n",
    "                i += 1\n",
    "            elif \"〕\" in note:  # key is already marked in the text with the format \"\\apost{a...}\".\n",
    "                key = note.split(\"〕\")[0].split(\"〔\")[0]\n",
    "                footdict[key] = \"\".join(note.split(key)[1:])\n",
    "            # print(word)\n",
    "            if word:  # find the position to insert footnote and mark\n",
    "                nfin = content.find(word) + len(word)\n",
    "                content = content[:nfin] + r\"\\apost{\" + key + \"}\" + content[nfin:]\n",
    "        if \"|#|\" in content:\n",
    "            content_new = []\n",
    "            for para in content.split(\"@\"):\n",
    "                content_new.append(para.split(\"|#|\"))\n",
    "            content = content_new\n",
    "        else:\n",
    "            content = content.split(\"@\")\n",
    "        \n",
    "        out[\"title\"] = title\n",
    "        out[\"author\"] = author\n",
    "        out[\"content\"] = content\n",
    "        out[\"remarks\"] = remarks\n",
    "        out[\"footnotes\"] = footdict\n",
    "        out[\"endnotes\"] = endnotes\n",
    "        out[\"vocabulary\"] = vocabulary\n",
    "        if grade:\n",
    "            out[\"grade\"] = grade\n",
    "    return title, out\n",
    "\n",
    "def text_content_to_tex_str(text, verbose=0, verseprop=0.5, format=\"散文\", footnotes={}, endnotes=[]):\n",
    "    \"\"\"convert the content of a text to text string ready for tex.\n",
    "    the format varies by genre:\n",
    "    散文、小说\n",
    "    书信\n",
    "    诗歌\n",
    "    剧本\n",
    "    \"\"\" \n",
    "    content = text[\"content\"]\n",
    "    if \"footnotes\" in text:\n",
    "        footnotes = text[\"footnotes\"]\n",
    "    if \"format\" in text:\n",
    "        format = text[\"format\"]\n",
    "    out = \"\"\n",
    "    if format in (\"散文\", \"小说\",):\n",
    "        out = \"\\n\\n\".join(content) + \"\\n\"\n",
    "    elif  format == \"书信\":\n",
    "        if verbose and not content[0].endswith(\"：\"):\n",
    "            print(\"错误：第一行不是抬头\")\n",
    "            return \"格式错误\\n\"\n",
    "        out = r\"\\noindent \" + content[0] + \"\\n\\n\" + wrap_method(\"vspace\", \"24pt\") + \"\\n\\n\"\n",
    "        toright = False\n",
    "        toright_content = \"\"\n",
    "        for line in content[1:]:\n",
    "            if line:\n",
    "                if toright:\n",
    "                    toright_content += line + \"\\n\\n\"\n",
    "                else:\n",
    "                    out += line + \"\\n\\n\"\n",
    "            else:\n",
    "                toright = True\n",
    "        out += wrap_method(\"vspace\", \"36pt\") + \"\\n\\n\"\n",
    "        out += wrap_env(\"flushright\", toright_content) + \"\\n\\n\"\n",
    "    elif  format == \"诗歌\":\n",
    "        if not isinstance(content[0], list):\n",
    "            content = [content]\n",
    "        \n",
    "        lineskip = \" \\\\\\\\\\n\"\n",
    "        # parskip = \"\\n\" + wrap_method(\"vspace\", \"4pt\") + \"\\n\\n\"\n",
    "        parskip = \"\\n\\n\"\n",
    "        out = parskip.join([wrap_env(\"verse\", lineskip.join(par) + \"\\n\", params=[str(verseprop)+\"\\\\linewidth\"]) for par in content])\n",
    "    elif format == \"剧本\":\n",
    "        name_set = text[\"characters\"]\n",
    "        for line in content:\n",
    "            if line.startswith(\"\\\\item[\"):\n",
    "                name = line.split(\"]\")[0][6:]\n",
    "                colored_name = r\"{\\color{\" + name_set[name] + r\"} \" + name + r\"}\"\n",
    "                out += \"\\\\item[\" + colored_name + \"]\" + \"]\".join(line.split(\"]\")[1:])\n",
    "            elif line.startswith(\"$\"):\n",
    "                colored_line = line\n",
    "                for name in name_set:\n",
    "                    colored_line = colored_line.replace(name, r\"{\\color{\" + name_set[name] + r\"} \" + name + r\"}\")\n",
    "                out += colored_line\n",
    "            else:\n",
    "                out += line\n",
    "            out += \"\\n\\n\"\n",
    "    for key in footnotes:\n",
    "        out = out.replace(\"apost{\"+key+\"}\", \"footnote{\" + footnotes[key] + \"}\")\n",
    "    return out\n",
    "\n",
    "def endnotes_to_str(endnotes, verbose=0, pinyin=False):\n",
    "    \"\"\"convert the endnotes to text string ready for tex.\"\"\"\n",
    "    out = \"\"\n",
    "    notes = \"\"\n",
    "    for note in endnotes:\n",
    "        if pinyin and note.startswith(\"〔\"):  # add pinyin\n",
    "            suite = note[1:].split(\"〕\")\n",
    "            notes += \"\\item \" + note[0] + r\"\\xpinyin*{\" + suite[0] + r\"}〕\" + \"〕\".join(suite[1:]) + \"\\n\"\n",
    "        else:\n",
    "            notes += \"\\item \" + note + \"\\n\"\n",
    "    if notes:\n",
    "        out = r\"\\newpage\" + \"\\n\\n\" + r\"\\textbf{注释}：\" + \"\\n\\n\" + r\"\\vspace{-1em}\" + \"\\n\\n\"\n",
    "        out += wrap_env(\"itemize\", r\"\\setlength\\itemsep{-0.2em}\" + \"\\n\" + notes)\n",
    "    return out\n",
    "\n",
    "def shizi_to_str(zis, n=8):\n",
    "    out = \"\\clearpage\" + \"\\n\\n\"\n",
    "    boxes = \"\"\n",
    "    i = 0\n",
    "    for zi in zis:\n",
    "        boxes += wrap_method(\"hanzibox\", zi)\n",
    "        i += 1\n",
    "        if i == n:\n",
    "            boxes += \"\\n\\n\"\n",
    "            i = 0\n",
    "    out += wrap_env(\"center\", boxes + \"\\n\\n\")\n",
    "    return out\n",
    "\n",
    "def xiezi_to_str(zis, ncol=2, nex=4, hspace=1):\n",
    "    out = \"\"\n",
    "    boxes = \"\"\n",
    "    i = 0\n",
    "    for zi in zis:\n",
    "        boxes += wrap_method(\"hanzibox\", zi)\n",
    "        for j in range(nex):\n",
    "            boxes += wrap_method(\"hanzibox\", \"\")\n",
    "        i += 1\n",
    "        if i == ncol:\n",
    "            boxes += \"\\n\\n\"\n",
    "            i = 0\n",
    "        else:\n",
    "            boxes += wrap_method(\"hspace\", f\"{hspace}em\")\n",
    "    out += boxes + \"\\n\\n\"\n",
    "    # out += wrap_env(\"center\", boxes + \"\\n\\n\")\n",
    "    return out\n",
    "\n",
    "def text_to_tex_str(text, typesettings={\"font\": {\"title\": {\"size\": 2}, \"plaintext\": {\"size\": \"normalsize\"}}, \"vspaces\": {\"after_title\": 12, \"after_author\": 6, \"after_content\": 6}}):\n",
    "    \"\"\"convert a text object to text string ready for tex\n",
    "    \"\"\"\n",
    "    out = \"\"\n",
    "    content = \"\"\n",
    "    # title_fontsize = typesettings[\"font\"][\"title\"][\"size\"]\n",
    "    # title = wrap_method(\"textbf\", zihao(title_fontsize) + \" \" + text[\"title\"]) + \"\\n\"\n",
    "    title = wrap_method(\"chapter\", text[\"title\"]) + \"\\n\\n\"\n",
    "    content += title\n",
    "    # content = wrap_env(\"center\", content) + \"\\n\"\n",
    "    # content += wrap_method(\"vspace\", f\"{typesettings['vspaces']['after_title']}pt\") + \"\\n\\n\"\n",
    "    content += wrap_env(typesettings[\"font\"][\"plaintext\"][\"size\"], \"\\n\" + text_content_to_tex_str(text) + \"\\n\")\n",
    "    # content += wrap_method(\"vspace\", f\"{typesettings['vspaces']['after_content']}pt\") + \"\\n\\n\"\n",
    "    out += content + \"\\n\\n\"\n",
    "    # out += wrap_method(\"newpage\", keep_wrapper=False) + \"\\n\\n\"\n",
    "    if \"endnotes\" in text:\n",
    "        out += endnotes_to_str(text[\"endnotes\"])\n",
    "    if \"shizi\" in text:\n",
    "        nchars = 10\n",
    "        if len(text[\"shizi\"]) % 10 == 1:\n",
    "            nchars = 8\n",
    "        out += shizi_to_str(text[\"shizi\"], n=nchars) + \"\\n\\n\"\n",
    "        if \"xiezi\" in text:\n",
    "            out += xiezi_to_str(text[\"xiezi\"]) + \"\\n\\n\"\n",
    "    return out\n",
    "\n",
    "def add_text(texts, title, content, format=\"散文\", tags=[]):\n",
    "    \"\"\"Add a text to the dictionary of texts.\n",
    "    Inputs:\n",
    "    texts (dict): dictionary of texts. title --> content.\n",
    "    title (str): title of the text.\n",
    "    content (dict): content of the text.\n",
    "    format (str): format of the text.\n",
    "    tags (list of str): tags to describe the text.\n",
    "    Output:\n",
    "    texts: updated dictionary of texts. \n",
    "    \"\"\"\n",
    "    if len(tags):\n",
    "        content[\"genre\"] = tags\n",
    "    if format == \"剧本\":\n",
    "        if title not in texts:\n",
    "            script_keys = []\n",
    "            for _, text in texts.items():\n",
    "                if text[\"format\"] == \"剧本\" and \"key\" in text:\n",
    "                    script_keys.append(int(text[\"key\"].split(\"-\")[1]))\n",
    "            if len(script_keys):\n",
    "                script_key = \"script-\" + str(max(script_keys) + 1)\n",
    "            else:\n",
    "                script_key = \"script-1\"\n",
    "                \n",
    "        else:\n",
    "            script_key = texts[title][\"key\"]\n",
    "        name_set, color_set = set_char_colors(content[\"content\"], script_key)\n",
    "        \n",
    "    texts[title] = content\n",
    "    if format == \"剧本\":\n",
    "        texts[title][\"key\"] = script_key\n",
    "        texts[title][\"characters\"] = name_set\n",
    "        texts[title][\"character_colors\"] = color_set\n",
    "    return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = {}\n",
    "packages[\"ctex\"] = []\n",
    "packages[\"titlesec\"] = []\n",
    "packages[\"xeCJK\"] = []\n",
    "packages[\"verse\"] = []\n",
    "packages[\"fontspec,xunicode,xltxtra\"] = []\n",
    "packages[\"xpinyin\"] = pinyin\n",
    "packages[\"geometry\"] = geometry\n",
    "packages[\"indentfirst\"] = []\n",
    "packages[\"pifont\"] = []\n",
    "packages[\"footmisc\"] = {\"declarations\": [\"perpage\", \"symbol*\"]}\n",
    "lineskip = \"24pt\"\n",
    "parskip = \"6pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新增课文：我为少男少女们歌唱\n"
     ]
    }
   ],
   "source": [
    "texts_xx = load_cn_json(\"../src/小学/阅读课文.json\")\n",
    "\n",
    "text_format = \"诗歌\"\n",
    "tags = [\"诗歌\", \"抒情\"]\n",
    "title, content = read_text(\"草稿.tex\", format=text_format)\n",
    "\n",
    "if title:\n",
    "    print(f\"新增课文：{title}\")\n",
    "    texts = add_text(texts_xx, title, content, text_format, tags)\n",
    "    dump_cn_json(\"../src/小学/阅读课文.json\", texts_xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_xx = load_cn_json(\"../src/小学/阅读课文.json\")\n",
    "\n",
    "booktitle = \"小学语文课文集萃\"\n",
    "header, footer = make_ctex_env(packages=packages, title=booktitle, parskip=parskip, lineskip=lineskip)\n",
    "typesettings = {}\n",
    "typesettings[\"vspaces\"] = {\"after_title\": 36, \"after_author\": 16, \"after_content\": 16}\n",
    "typesettings[\"font\"] = {\"plaintext\": {\"size\": \"large\"}}\n",
    "\n",
    "with open(\"小学现代文阅读课文.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(header + \"\\n\")\n",
    "    for title, text in sort_dict_with(texts_xx):\n",
    "        # print(title)\n",
    "        f.write(text_to_tex_str(text, typesettings=typesettings) + \"\\n\")\n",
    "    f.write(footer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 年级 (16)\n",
      "['狼和小羊', '翠鸟', '揠苗助长', '守株待兔', '初冬']\n",
      "['秋天', '坐井观天', '骆驼和羊', '狐狸和乌鸦', '曹冲称象']\n",
      "['乌鸦喝水', '狐狸和公鸡', '老狼分饼', '叶公好龙', '十二月花名歌']\n",
      "['画蛇添足']\n",
      "3 年级 (48)\n",
      "['茅以升立志造桥', '美丽的小兴安岭', '大海的歌', '让我们荡起双桨', '小马过河']\n",
      "['刻舟求剑 ', '八角楼上', '赵州桥', '南京长江大桥', '雨']\n",
      "['放风筝', '荷花', '掩耳盗铃', '自相矛盾', '滥竽充数']\n",
      "['惊弓之鸟', '绿色的办公室', '黄继光', '颐和园', '五彩池']\n",
      "['青蛙的眼睛', '爬山虎的脚', '课间十分钟', '日出', '捞铁牛']\n",
      "['纸上谈兵', '趵突泉', '鸟的天堂', '桂林山水', '天安门广场']\n",
      "['火烧云', '卢沟桥的狮子', '海上日出', '董存瑞舍身炸碉堡', '十里长街送总理']\n",
      "['狐狸和山羊', '燕子', '晏子使楚', '狼牙山五壮士', '我的战友邱少云']\n",
      "['草原', '马踏飞燕', '伏尔加河上的纤夫', '牛郎织女的故事', '搭船的鸟']\n",
      "['狐假虎威', '塞翁失马', '买椟还珠']\n",
      "4 年级 (54)\n",
      "['我和企鹅', '白求恩大夫（节选改编）', '我的弟弟“小萝卜头”', '帐篷', '参观人民大会堂']\n",
      "['海底世界', '故乡的杨梅', '杏儿熟了', '春蚕', '李时珍']\n",
      "['画杨桃', '珍贵的教科书', '爸爸和书', '小珊迪', '劳动最有滋味']\n",
      "['花生花', '种子', '观潮', '高大的皂荚树', '海滨小城']\n",
      "['蝙蝠和雷达', '各种各样的玻璃', '糖画', '西门豹', '中国石']\n",
      "['古井', '峨眉道上', '太阳', '绿叶', '九寨沟']\n",
      "['兵马俑', '冬眠', '七月的天山', '小英雄雨来', '参观刘家峡水电站']\n",
      "['小站', '挑山工', '可爱的草塘', '雪猴', '鲸']\n",
      "['圆明园的毁灭', '喂药（汤姆索亚历险记节选）', '阁楼（小公主节选）', '冀中的地道战', '草船借箭']\n",
      "['田忌赛马', '记金华的双龙洞', '丰碑', '镜泊湖奇观', '伟大的友谊']\n",
      "['詹天佑', '东郭先生与狼', '瑞雪图', '彭德怀速写']\n",
      "5 年级 (41)\n",
      "['长城', '森林的主人', '鱼游到了纸上', '蟋蟀的住宅', '高梁情']\n",
      "['只有一个地球', '一个苹果', '出海（老人与海节选）', '养花', '蛇与庄稼']\n",
      "['彩色的翅膀', '飞夺泸定桥', '囚歌', '我的“自白”书', '给颜黎民的信']\n",
      "['落花生', '难忘的一课', '毛主席在花山', '开国大典', '狱中联欢']\n",
      "['凡卡', '金色的鱼钩', '一夜的工作', '林海', '第一场雪']\n",
      "['灯光', '卖火柴的小女孩', '将相和', '景阳冈', '梅花魂']\n",
      "['为人民服务', '难忘的启蒙', '珊瑚', '三亚落日', '富饶的西沙群岛']\n",
      "['带刺的朋友', '科学家竺可桢', '白鹭', '向祖国致敬', '王二小']\n",
      "['啊，姑娘再见！']\n",
      "6 年级 (23)\n",
      "['菩萨蛮·大柏地', '穷人', '琥珀', '十六年前的回忆', '夜莺的歌声']\n",
      "['花潮', '少年闰土', '青山', '草方格', '北京的春节']\n",
      "['他们那时候多有趣啊', '故宫博物院', '海的颜色', '有的人', '冬天的济南']\n",
      "['撤离班加西', '北约轰炸大使馆', '在巴黎传递奥运火炬', '美猴王当弼马温', '海滨仲夏夜']\n",
      "['延安的秋天', '绿宝团', '我为少男少女们歌唱']\n"
     ]
    }
   ],
   "source": [
    "texts_xx = load_cn_json(\"../src/小学/阅读课文.json\")\n",
    "\n",
    "grade_count = {}\n",
    "title_by_grade = {}\n",
    "title_by_genre = {}\n",
    "genre_by_grade = {}\n",
    "for title, text in texts_xx.items():\n",
    "    if \"grade\" not in text:\n",
    "        text[\"grade\"] = 1\n",
    "    g = text[\"grade\"]\n",
    "    if g not in grade_count:\n",
    "        grade_count[g] = 0\n",
    "    if g not in title_by_grade:\n",
    "        title_by_grade[g] = []\n",
    "    if g not in genre_by_grade:\n",
    "        genre_by_grade[g] = {}\n",
    "    for genre in text[\"genre\"]:\n",
    "        if genre not in genre_by_grade[g]:\n",
    "            genre_by_grade[g][genre] = []\n",
    "        if genre not in title_by_genre:\n",
    "            title_by_genre[genre] = []\n",
    "    grade_count[text[\"grade\"]] += 1\n",
    "    title_by_grade[text[\"grade\"]].append(title)\n",
    "    for genre in text[\"genre\"]:\n",
    "        genre_by_grade[g][genre].append(title)\n",
    "        title_by_genre[genre].append(title)\n",
    "\n",
    "for g in title_by_grade:\n",
    "    print(f\"{g} 年级 ({len(title_by_grade[g])})\")\n",
    "    nice_print(title_by_grade[g])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中学"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'猫'}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_xx = load_cn_json(\"../src/小学/阅读课文.json\")\n",
    "texts_cz = load_cn_json(\"../src/中学/阅读课文.json\")\n",
    "\n",
    "titles1 = set(list(texts_xx.keys()))\n",
    "titles2 = set(list(texts_cz.keys()))\n",
    "\n",
    "titles1 & titles2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['绿', '关于圆明园的一封信', '断章', '未选择的路', '老人与海']\n",
      "['看云识天气', '记一辆纺车', '从百草园到三味书屋', '藤野先生', '谁是最可爱的人']\n",
      "['反对党八股', '纪念白求恩', '变色龙', '雨巷', '播种季的傍晚']\n",
      "['荷塘月色', '繁星', '回忆我的母亲', '洱海一枝春', '怀疑与学问']\n",
      "['中国石拱桥', '向沙漠进军', '范进中举', '中国人失掉自信力了吗', '海燕']\n",
      "['土地的誓言', '包身工', '阿Q正传', '“友邦惊诧”论', '反对自由主义']\n",
      "['畏惧错误就是毁灭进步', '假如生活欺骗了你', '愚公移山', '我用残损的手掌', '船夫曲']\n",
      "['天上的街市', '消息两则', '雄伟的人民大会堂', '一', '国王的新衣']\n",
      "['理想的阶梯', '白求恩传', '中国人民寻求救国真理的道路', '在《人民报》创刊周年纪念会上的演说', '祝福']\n",
      "['孔乙己', '匆匆', '发问的精神', '批评与自我批评', '求雨']\n",
      "['假使我们不去打仗', '大卫·科波菲尔', '夜', '社戏', '桨声灯影里的秦淮河']\n",
      "['紫藤萝瀑布', '我的老师', '聪明人和傻子和奴才', '老山界', '最后一次的讲演']\n",
      "['快乐王子', '故乡', '错误', '拿来主义', '三年以后']\n",
      "['树', '竞选州长', '论雷峰塔的倒掉', '生命的意义', '故都的秋']\n",
      "['威尼斯商人', '在烈日和暴雨下', '《呐喊》自序', '我的叔叔于勒', '乡愁']\n",
      "['万紫千红的花', '套中人', '驿路梨花', '鲁提辖拳打镇关西', '致杨振宁']\n",
      "['花市', '生物的入侵者', '太空一日', '漫谈无理数', '静寂的园子']\n",
      "['麦琪的礼物', '桥', '复活', '食物从何处来', '葫芦僧判断葫芦案']\n",
      "['车库里的龙', '白杨礼赞', '大自然的语言', '墙上的斑点', '春']\n",
      "['药', '东方红一号发射', '刘胡兰', '阿长与山海经', '应有真正的格物致知精神']\n",
      "['我爱这土地', '背影', '记念刘和珍君', '卧看牵牛织女星', '猫']\n",
      "['最后一课', '挖荠菜', '雷雨', '林教头风雪山神庙', '苏州园林']\n",
      "['七根火柴', '多收了三五斗', '季节就这样逝去', '《农村调查》序言', '松明']\n",
      "['人类的语言', '关于自由落体的讨论', '想和做', '济南的冬天', '人民英雄永垂不朽']\n"
     ]
    }
   ],
   "source": [
    "nice_print(list(titles2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 现代文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = {}\n",
    "packages[\"ctex\"] = []\n",
    "packages[\"titlesec\"] = []\n",
    "packages[\"xeCJK\"] = []\n",
    "packages[\"verse\"] = []\n",
    "packages[\"fontspec,xunicode,xltxtra\"] = []\n",
    "packages[\"xpinyin\"] = pinyin\n",
    "packages[\"geometry\"] = geometry\n",
    "packages[\"indentfirst\"] = []\n",
    "packages[\"pifont\"] = []\n",
    "packages[\"enumitem\"] = []\n",
    "packages[\"footmisc\"] = {\"declarations\": [\"perpage\", \"symbol*\"]}\n",
    "xcolor = {}\n",
    "xcolor[\"declarations\"] = [\"table\", \"dvipsnames\"]\n",
    "packages[\"xcolor\"] = xcolor\n",
    "\n",
    "typesettings = {}\n",
    "typesettings[\"vspaces\"] = {\"after_title\": 36, \"after_author\": 16, \"after_content\": 16}\n",
    "typesettings[\"font\"] = {\"plaintext\": {\"size\": \"normalsize\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_zs(path):\n",
    "    lines = read(\"草稿.tex\")\n",
    "\n",
    "    out = []\n",
    "    zs = False\n",
    "    for line in lines:\n",
    "        if line[0] in \"0987654321\":\n",
    "            zs = True\n",
    "            continue\n",
    "        if zs:\n",
    "            parts = line.split(\"：\")\n",
    "            out.append(f\"注释：〔{parts[0]}〕\" + \"：\".join(parts[1:]))\n",
    "            zs = False\n",
    "        else:\n",
    "            newline =\"\".join([w for w in line if w not in \"0987654321\"])\n",
    "            out.append(newline)\n",
    "\n",
    "    with open(\"草稿.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新增课文：项链\n"
     ]
    }
   ],
   "source": [
    "texts_cz = load_cn_json(\"../src/中学/阅读课文.json\")\n",
    "\n",
    "text_format = \"散文\"\n",
    "tags = [\"小说\", \"批判现实主义\"]\n",
    "title, content = read_text(\"草稿.tex\", format=text_format)\n",
    "\n",
    "if title:\n",
    "    print(f\"新增课文：{title}\")\n",
    "    texts = add_text(texts_cz, title, content, text_format, tags)\n",
    "    dump_cn_json(\"../src/中学/阅读课文.json\", texts_cz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "booktitle = \"中学语文课文集萃\"\n",
    "texts_cz = load_cn_json(\"../src/中学/阅读课文.json\")\n",
    "\n",
    "lineskip = \"24pt\"\n",
    "parskip = \"6pt\"\n",
    "package_update_xcolor(packages, texts_cz)\n",
    "header, footer = make_ctex_env(packages=packages, title=booktitle, parskip=parskip, lineskip=lineskip)\n",
    "with open(\"中学现代文阅读课文.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(header + \"\\n\")\n",
    "    for title, text in sort_dict_with(texts_cz):\n",
    "        # print(title)\n",
    "        f.write(text_to_tex_str(text, typesettings=typesettings) + \"\\n\")\n",
    "        # break\n",
    "    f.write(footer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7, 26), (8, 26), (9, 26), (10, 27), (11, 14), (12, 2)]\n",
      "121\n",
      "['土地的誓言', '未选择的路', '东方红一号发射', '最后一课', '花市']\n",
      "['藤野先生', '孔乙己', '鲁提辖拳打镇关西', '中国人民寻求救国真理的道路', '《农村调查》序言']\n",
      "['竞选州长', '我的叔叔于勒', '葫芦僧判断葫芦案', '卧看牵牛织女星', '变色龙']\n",
      "['威尼斯商人', '夜', '拿来主义', '快乐王子', '多收了三五斗']\n",
      "['乡愁', '错误', '白求恩传', '聪明人和傻子和奴才', '求雨']\n",
      "['船夫曲']\n"
     ]
    }
   ],
   "source": [
    "grade = 9\n",
    "print([(g, grade_count[g]) for g in range(7, 13)])\n",
    "print(sum([grade_count[g] for g in range(7, 13)]))\n",
    "nice_print(title_by_grade[grade])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从百草园到三味书屋\n",
      "阿长与山海经\n",
      "论雷峰塔的倒掉\n",
      "“友邦惊诧”论\n",
      "社戏\n",
      "故乡\n",
      "藤野先生\n",
      "孔乙己\n",
      "中国人失掉自信力了吗\n",
      "拿来主义\n",
      "祝福\n",
      "聪明人和傻子和奴才\n",
      "记念刘和珍君\n",
      "《呐喊》自序\n",
      "药\n",
      "阿Q正传（节选）\n"
     ]
    }
   ],
   "source": [
    "for title, text in texts_cz.items():\n",
    "    if text[\"author\"] == \"鲁迅\":\n",
    "        if \"节选\" in text[\"genre\"]:\n",
    "            print(title+ \"（节选）\")\n",
    "        else:\n",
    "            print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 ['记叙文']\n",
      "58 ['散文']\n",
      "26 ['说明文']\n",
      "25 ['寓言']\n",
      "23 ['描写文']\n",
      "21 ['小说']\n",
      "19 ['回忆']\n",
      "18 ['文言文翻译']\n",
      "15 ['地方介绍']\n",
      "14 ['人物', '成语故事']\n",
      "12 ['科普', '报告文学']\n",
      "10 ['游记']\n",
      "9 ['名人故事', '抒情']\n",
      "6 ['诗歌']\n",
      "5 ['事物介绍']\n",
      "4 ['动物', '纪实文学', '纪实']\n",
      "3 ['人物介绍', '借事说理', '议论文', '经典']\n",
      "2 ['借物喻理', '书信', '童话', '写景', '描写']\n",
      "1 ['古文翻译', '笔记', '借物抒情', '科幻', '神话传说', '景物', '幻想', '名著', '节选', '声明', '应用文', '言志', '民俗', '植物', '时令']\n"
     ]
    }
   ],
   "source": [
    "texts_xx = load_cn_json(\"../src/小学/阅读课文.json\")\n",
    "grade_count = {}\n",
    "title_by_grade = {}\n",
    "title_by_genre = {}\n",
    "genre_by_grade = {}\n",
    "for title, text in texts_xx.items():\n",
    "    if \"grade\" not in text:\n",
    "        text[\"grade\"] = 1\n",
    "    g = text[\"grade\"]\n",
    "    if g not in grade_count:\n",
    "        grade_count[g] = 0\n",
    "    if g not in title_by_grade:\n",
    "        title_by_grade[g] = []\n",
    "    if g not in genre_by_grade:\n",
    "        genre_by_grade[g] = {}\n",
    "    for genre in text[\"genre\"]:\n",
    "        if genre not in genre_by_grade[g]:\n",
    "            genre_by_grade[g][genre] = []\n",
    "        if genre not in title_by_genre:\n",
    "            title_by_genre[genre] = []\n",
    "    grade_count[text[\"grade\"]] += 1\n",
    "    title_by_grade[text[\"grade\"]].append(title)\n",
    "    for genre in text[\"genre\"]:\n",
    "        genre_by_grade[g][genre].append(title)\n",
    "        title_by_genre[genre].append(title)\n",
    "\n",
    "res = [(k,len(v)) for k, v in title_by_genre.items()]\n",
    "\n",
    "# alist = res\n",
    "def printsort_int(alist, rev=False):\n",
    "    ma = max([b for (_, b) in alist])\n",
    "    tem = [[] for _ in range(ma+1)]\n",
    "    for (a, b) in alist:\n",
    "        tem[b].append(a)\n",
    "    \n",
    "    if rev:\n",
    "        for i, a in enumerate(tem[::-1]):\n",
    "            if len(a):\n",
    "                print(ma-i, a)\n",
    "    else:\n",
    "        for i, a in enumerate(tem):\n",
    "            if len(a):\n",
    "                print(i, a)\n",
    "\n",
    "printsort_int(res, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 ['小说']\n",
      "27 ['散文']\n",
      "26 ['经典']\n",
      "21 ['抒情']\n",
      "17 ['议论文']\n",
      "16 ['诗歌', '节选', '浪漫主义']\n",
      "14 ['自然', '回忆', '说明文']\n",
      "12 ['现实主义']\n",
      "11 ['科普']\n",
      "10 ['人物']\n",
      "9 ['景物', '演讲', '批判现实主义']\n",
      "8 ['叙事']\n",
      "7 ['记叙文', '倡议', '论述']\n",
      "6 ['社会百态']\n",
      "5 ['纪实', '意象']\n",
      "4 ['四季', '讽刺', '建筑', '鼓动', '象征主义']\n",
      "3 ['名著']\n",
      "2 ['童话', '借物抒情', '动物', '报告文学', '书信', '驳论', '议论', '想象', '序言', '游记', '意识流']\n",
      "1 ['悼词', '抗议', '友情', '纪实文学', '刘胡兰', '植物', '亲情', '提出问题', '戏剧', '墙头诗', '新闻稿', '对话录', '科学', '推理', '辩论', '批评', '话剧', '传记', '寓言', '纪念', '都市童话', '插叙', '回信', '说理', '阐述']\n"
     ]
    }
   ],
   "source": [
    "# [title for title in texts_cz if texts_cz[title]['author'] == \"鲁迅\"]\n",
    "texts_cz = load_cn_json(\"../src/中学/阅读课文.json\")\n",
    "grade_count = {}\n",
    "title_by_grade = {}\n",
    "title_by_genre = {}\n",
    "genre_by_grade = {}\n",
    "for title, text in texts_cz.items():\n",
    "    g = text[\"grade\"]\n",
    "    if g not in grade_count:\n",
    "        grade_count[g] = 0\n",
    "    if g not in title_by_grade:\n",
    "        title_by_grade[g] = []\n",
    "    if g not in genre_by_grade:\n",
    "        genre_by_grade[g] = {}\n",
    "    for genre in text[\"genre\"]:\n",
    "        if genre not in genre_by_grade[g]:\n",
    "            genre_by_grade[g][genre] = []\n",
    "        if genre not in title_by_genre:\n",
    "            title_by_genre[genre] = []\n",
    "    grade_count[text[\"grade\"]] += 1\n",
    "    title_by_grade[text[\"grade\"]].append(title)\n",
    "    for genre in text[\"genre\"]:\n",
    "        genre_by_grade[g][genre].append(title)\n",
    "        title_by_genre[genre].append(title)\n",
    "\n",
    "res = [(k,len(v)) for k, v in title_by_genre.items()]\n",
    "\n",
    "# alist = res\n",
    "def printsort_int(alist, rev=False):\n",
    "    ma = max([b for (_, b) in alist])\n",
    "    tem = [[] for _ in range(ma+1)]\n",
    "    for (a, b) in alist:\n",
    "        tem[b].append(a)\n",
    "    \n",
    "    if rev:\n",
    "        for i, a in enumerate(tem[::-1]):\n",
    "            if len(a):\n",
    "                print(ma-i, a)\n",
    "    else:\n",
    "        for i, a in enumerate(tem):\n",
    "            if len(a):\n",
    "                print(i, a)\n",
    "\n",
    "printsort_int(res, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7: 43, 8: 36, 9: 24, 10: 15, 12: 2, 11: 1}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nice_print(title_by_genre[\"自然\"])\n",
    "grade_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(text):\n",
    "    out = ''\n",
    "    content = text['content']\n",
    "    if text['format'] == '诗歌':\n",
    "        for block in content:\n",
    "            for line in block:\n",
    "                out += line\n",
    "    else:\n",
    "        for line in content:\n",
    "            out += line\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_cz = load_cn_json(\"../src/小学/阅读课文.json\")\n",
    "\n",
    "for title, text in texts_cz.items():\n",
    "    if text[\"format\"] == \"诗歌\":\n",
    "        continue\n",
    "    footnotes = text['footnotes']\n",
    "    foots_new = {}\n",
    "    keybase = \"fn\"\n",
    "    content = text['content']\n",
    "    content_new = []\n",
    "    s = get_content(text)\n",
    "    if s.find(\"footnote\") < 0:  # no foonote numerated\n",
    "        foots_new = {}\n",
    "        i = 0\n",
    "        out = \"|#|\".join(text[\"content\"])\n",
    "        for note in footnotes:\n",
    "            word = \"\"\n",
    "            if note.startswith(\"〔\"):\n",
    "                word = note.split(\"〕\")[0][1:]\n",
    "                key = keybase + str(i+1)\n",
    "                foots_new[key] = note\n",
    "                i += 1\n",
    "            elif \"〕\" in note:  # key is already marked in the text with the format \"\\apost{a...}\".\n",
    "                key = note.split(\"〕\")[0].split(\"〔\")[0]\n",
    "                foots_new[key] = \"\".join(note.split(key)[1:])\n",
    "            # print(word)\n",
    "            if word:  # find the position to insert footnote and mark\n",
    "                nfin = out.find(word) + len(word)\n",
    "                out = out[:nfin] + r\"\\apost{\" + key + \"}\" + out[nfin:]\n",
    "        content_new = out.split(\"|#|\")\n",
    "    else:  # footnote numerated\n",
    "        for i, note in enumerate(footnotes):\n",
    "            key = keybase + str(i+1)\n",
    "            foots_new[key] = note\n",
    "        i = 0  # counter for line\n",
    "        j = 0  # counter for note\n",
    "        line = content[i]\n",
    "        while i < len(content) and j < len(footnotes):\n",
    "            if line.find(\"footnote{\"+str(j+1)+\"}\") < 0:  # if you cannot find a note in this line\n",
    "                content_new.append(line)  # get to original line\n",
    "                i += 1\n",
    "                line = content[i]  # load the next line\n",
    "            else:  # if you find a note in this line \n",
    "                key = keybase + str(j+1)\n",
    "                line = line.replace(\"footnote{\"+str(j+1)+\"}\", \"apost{\" + key + \"}\")  # replace\n",
    "                j += 1  # move to the next note\n",
    "        content_new.append(line)\n",
    "        i += 1\n",
    "        while i < len(content):\n",
    "            line = content[i]\n",
    "            content_new.append(line)\n",
    "            i += 1            \n",
    "            \n",
    "    text['footnotes'] = foots_new\n",
    "    text['content'] = content_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_cn_json(\"../src/小学/阅读课文.json\", texts_cz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = load_cn_json(\"../src/小学/阅读课文.json\")\n",
    "\n",
    "for title, text in texts.items():\n",
    "    if isinstance(text[\"footnotes\"], list):\n",
    "        text[\"footnotes\"] = {}\n",
    "\n",
    "dump_cn_json(\"../src/小学/阅读课文.json\", texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 识字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "texts_sz = load_cn_json(\"../src/小学/发蒙识字.json\")\n",
    "\n",
    "# arrange the texts by numero\n",
    "nx = np.sort(np.array([text['numero'] for idx, text in texts_sz.items()]))\n",
    "texts_nu = []\n",
    "for i in nx:\n",
    "    for idx, text in texts_sz.items():\n",
    "        if text['numero'] == i:\n",
    "            texts_nu.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_sz = load_cn_json(\"../src/小学/发蒙识字.json\")\n",
    "\n",
    "for title, text in texts_sz.items():\n",
    "    text[\"format\"] = \"散文\"\n",
    "    text[\"footnotes\"] = {}\n",
    "    text[\"endnotes\"] = []\n",
    "\n",
    "# dump_cn_json(\"../src/小学/发蒙识字.json\", texts_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 3\n",
      "20 15\n",
      "30 11\n",
      "40 10\n",
      "50 10\n",
      "60 8\n",
      "70 7\n",
      "80 6\n",
      "90 7\n",
      "100 6\n",
      "110 11\n",
      "120 8\n",
      "130 6\n",
      "140 9\n",
      "150 8\n",
      "160 7\n",
      "170 4\n",
      "175 7\n",
      "180 7\n",
      "190 5\n",
      "200 8\n",
      "210 8\n",
      "220 6\n",
      "230 7\n",
      "240 4\n",
      "250 7\n",
      "260 7\n",
      "270 7\n",
      "280 6\n",
      "285 8\n",
      "290 7\n",
      "300 8\n",
      "350 9\n",
      "370 8\n",
      "390 8\n",
      "400 6\n"
     ]
    }
   ],
   "source": [
    "for text in texts_nu:\n",
    "    print(text[\"numero\"], len(text[\"xiezi\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是中国人 9 ['中', '人', '文', '我', '上', '学', '爱', '国', '了']\n",
      "一二三四五 28 ['一', '二', '三', '四', '五', '金', '木', '水', '火', '土', '天', '地', '日', '月', '分', '见', '下', '今', '古']\n",
      "人 38 ['头', '面', '身', '手', '足', '口', '舌', '目', '耳', '心']\n",
      "田 48 ['山', '川', '风', '云', '雨', '田', '力', '禾', '苗', '实']\n",
      "比大小 58 ['六', '七', '八', '九', '十', '比', '大', '小', '多', '少']\n",
      "山村 72 ['石', '不', '青', '鸡', '犬', '叫', '农', '牛', '马', '闻', '村', '肥', '路', '归']\n",
      "开门 80 ['有', '开', '门', '爸', '妈', '在', '个', '只']\n",
      "你我他 86 ['生', '是', '你', '他', '也', '们']\n",
      "田鸟 95 ['黄', '里', '麦', '鸟', '来', '飞', '吹', '点', '去']\n",
      "山羊 100 ['羊', '草', '吃', '谁', '的']\n",
      "方向 115 ['方', '早', '向', '太', '阳', '走', '边', '前', '后', '左', '右', '东', '南', '西', '北']\n",
      "我有一个家 125 ['儿', '子', '男', '女', '哥', '弟', '姐', '妹', '和', '家']\n",
      "看地图 130 ['外', '出', '入', '看', '图']\n",
      "工农兵 144 ['工', '兵', '士', '民', '量', '好', '习', '起', '团', '结', '保', '卫', '世', '界']\n",
      "这是什么 148 ['什', '么', '这', '那']\n",
      "你吃什么 157 ['兔', '虫', '猴', '猫', '捉', '桃', '花', '黑', '白']\n",
      "谁比我高 161 ['高', '屋', '到', '说']\n",
      "时间 170 ['季', '年', '时', '秒', '现', '还', '没', '半', '间']\n",
      "问路 181 ['问', '先', '往', '公', '园', '直', '再', '就', '怎', '请', '谢']\n",
      "你叫什么名字 193 ['名', '字', '王', '李', '张', '刘', '赵', '陈', '吴', '杨', '姓', '光']\n",
      "画 201 ['远', '近', '色', '声', '听', '惊', '春', '画']\n",
      "春雨 210 ['要', '啦', '吧', '种', '果', '树', '发', '芽', '长']\n",
      "小猫读书 220 ['干', '把', '打', '读', '书', '页', '喵', '会', '脚', '合']\n",
      "今天天气好 229 ['气', '两', '朵', '几', '背', '包', '照', '空', '当']\n",
      "车子吃什么油 234 ['油', '车', '电', '汽', '用']\n",
      "小舟 241 ['弯', '舟', '尖', '坐', '闪', '星', '蓝']\n",
      "我有一张床 250 ['床', '席', '被', '枕', '柜', '台', '灯', '衣', '服']\n",
      "我的笔盒 258 ['盒', '红', '铅', '尺', '橡', '皮', '笔', '支']\n",
      "找朋友 266 ['找', '呀', '朋', '友', '笑', '敬', '礼', '握']\n",
      "你开心吗？ 276 ['尾', '巴', '跳', '摇', '拍', '叽', '咕', '觉', '得', '嘴']\n",
      "切西瓜 283 ['拿', '刀', '切', '瓜', '块', '片', '成']\n",
      "秋天 290 ['凉', '群', '叶', '从', '排', '落', '雁']\n",
      "画彩虹 298 ['布', '彩', '虹', '想', '橙', '加', '紫', '绿']\n",
      "中秋 305 ['秋', '节', '饼', '巷', '圆', '最', '明']\n",
      "拍皮球 314 ['球', '数', '夏', '汗', '玩', '毛', '巾', '冰', '喝']\n",
      "你知不知道 327 ['知', '道', '广', '深', '海', '香', '老', '虎', '肉', '答', '案', '自', '然']\n",
      "雪地里的小画家 339 ['雪', '鸭', '狗', '步', '蛙', '睡', '洞', '它', '竹', '为', '梅', '枫']\n",
      "二月二 352 ['龙', '户', '抬', '使', '耕', '雷', '万', '物', '细', '绵', '似', '美', '酒']\n",
      "菜市场 365 ['菜', '买', '市', '丝', '豆', '姜', '卜', '葱', '场', '萝', '茄', '柿', '兰']\n",
      "大扫除 382 ['扫', '抹', '动', '活', '始', '除', '板', '齐', '拖', '提', '桶', '亮', '堂', '窗', '净', '快', '乐']\n",
      "东海龙宫 393 ['井', '乌', '流', '宫', '晶', '住', '宝', '贝', '玉', '夜', '珠']\n",
      "江南 399 ['江', '可', '采', '何', '莲', '戏']\n"
     ]
    }
   ],
   "source": [
    "ziji = {}\n",
    "nz = 0\n",
    "zinumbs = []\n",
    "zicount = []\n",
    "for text in texts_nu:\n",
    "    zis = []\n",
    "    for zi in text['shizi']:\n",
    "        if zi not in ziji:\n",
    "            ziji[zi] = 0\n",
    "            zis.append(zi)\n",
    "    n = len(zis)\n",
    "    nz += n\n",
    "    zinumbs.append(n)\n",
    "    zicount.append(nz)\n",
    "    print(text['title'], nz, zis)\n",
    "\n",
    "zinumbs = np.array(zinumbs)\n",
    "zicount = np.array(zicount)\n",
    "# print(zinumbs)\n",
    "# print(zicount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(zinumbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 1 total 5 rest 0\n",
      "level 2 total 12 rest 0\n",
      "level 3 total 24 rest 3\n",
      "['着', '她', '以']\n",
      "level 4 total 38 rest 12\n",
      "['而', '过', '能', '对', '于', '之', '都', '如', '事', '第']\n",
      "['样', '作']\n",
      "level 5 total 61 rest 32\n",
      "['总', '无', '情', '己', '但', '些', '所', '同', '又', '行']\n",
      "['意', '期', '经', '回', '位', '因', '很', '给', '法', '斯']\n",
      "['次', '者', '已', '亲', '其', '进', '此', '话', '常', '与']\n",
      "['正', '感']\n",
      "level 6 total 92 rest 47\n",
      "['理', '尔', '定', '本', '特', '做', '孩', '相', '将', '全']\n",
      "['信', '重', '机', '每', '并', '别', '真', '新', '才', '便']\n",
      "['夫', '部', '像', '眼', '等', '体', '却', '主', '利', '受']\n",
      "['表', '德', '克', '代', '员', '许', '零', '由', '死', '安']\n",
      "['写', '性', '或', '难', '望', '教', '命']\n",
      "level 7 total 148 rest 90\n",
      "['更', '拉', '神', '记', '处', '让', '母', '父', '应', '平']\n",
      "['报', '关', '放', '至', '认', '接', '告', '内', '英', '军']\n",
      "['候', '岁', '度', '带', '解', '任', '原', '变', '通', '师']\n",
      "['立', '象', '失', '满', '战', '格', '音', '轻', '条', '呢']\n",
      "['病', '达', '完', '求', '清', '化', '业', '思', '非', '罗']\n",
      "['钱', '积', '吗', '语', '元', '喜', '曾', '离', '科', '言']\n",
      "['欢', '约', '各', '即', '指', '反', '题', '必', '该', '论']\n",
      "['交', '终', '林', '医', '晚', '制', '决', '传', '运', '及']\n",
      "['则', '房', '院', '苦', '品', '产', '精', '视', '连', '司']\n"
     ]
    }
   ],
   "source": [
    "s7 = load_cn_json(\"simple700.json\")\n",
    "f9 = load_cn_json(\"frequent1000.json\")\n",
    "\n",
    "nin = []\n",
    "n = 0\n",
    "for lv in f9[:7]:\n",
    "    ni = []\n",
    "    n += 1\n",
    "    for zi in lv:\n",
    "        if zi in ziji:\n",
    "            pass\n",
    "        else:\n",
    "            ni.append(zi)\n",
    "    nin.append(ni)\n",
    "    print(\"level\", n, \"total\", len(lv), \"rest\", len(ni))\n",
    "    if ni:\n",
    "        nice_print(ni, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = {}\n",
    "packages[\"ctex\"] = []\n",
    "packages[\"titlesec\"] = []\n",
    "packages[\"xeCJK\"] = []\n",
    "packages[\"verse\"] = []\n",
    "packages[\"fontspec,xunicode,xltxtra\"] = []\n",
    "packages[\"xpinyin\"] = pinyin\n",
    "packages[\"hanzibox\"] = hanzibox\n",
    "packages[\"geometry\"] = geometry\n",
    "packages[\"indentfirst\"] = []\n",
    "packages[\"pifont\"] = []\n",
    "packages[\"enumitem\"] = []\n",
    "packages[\"footmisc\"] = {\"declarations\": [\"perpage\", \"symbol*\"]}\n",
    "xcolor = {}\n",
    "xcolor[\"declarations\"] = [\"table\", \"dvipsnames\"]\n",
    "packages[\"xcolor\"] = xcolor\n",
    "\n",
    "typesettings = {}\n",
    "typesettings[\"vspaces\"] = {\"after_title\": 36, \"after_author\": 16, \"after_content\": 16}\n",
    "typesettings[\"font\"] = {\"plaintext\": {\"size\": \"large\"}}\n",
    "\n",
    "booktitle = \"发蒙识字\"\n",
    "texts_sz = load_cn_json(\"../src/小学/发蒙识字.json\")\n",
    "\n",
    "lineskip = \"24pt\"\n",
    "parskip = \"6pt\"\n",
    "package_update_xcolor(packages, texts_sz)\n",
    "header, footer = make_ctex_env(packages=packages, title=booktitle, parskip=parskip, lineskip=lineskip)\n",
    "with open(\"发蒙识字.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(header + \"\\n\")\n",
    "    for title, text in sort_dict_with(texts_sz, key=\"numero\"):\n",
    "        # print(title)\n",
    "        f.write(text_to_tex_str(text, typesettings=typesettings) + \"\\n\")\n",
    "        # break\n",
    "    f.write(footer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hanzi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
